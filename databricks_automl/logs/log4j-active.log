25/06/09 05:17:58 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:18:05 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:18:05 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:18:11 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:18:16 INFO SecurityManager: Changing view acls to: root
25/06/09 05:18:16 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:18:16 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:18:16 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:18:19 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:18:20 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:18:20 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:18:20 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:18:20 INFO ResourceUtils: ==============================================================
25/06/09 05:18:20 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:18:20 INFO ResourceUtils: ==============================================================
25/06/09 05:18:20 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:18:20 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:18:20 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:18:20 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:18:14 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:18:20 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:18:20 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:18:21 INFO SecurityManager: Changing view acls to: root
25/06/09 05:18:21 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:18:21 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:18:21 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:18:21 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:18:21 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:18:25 INFO Utils: Successfully started service 'sparkDriver' on port 38437.
25/06/09 05:18:25 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:18:25 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:18:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:18:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:18:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:18:25 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-0535b161-e6ce-4502-b34e-7a98038fb00c
25/06/09 05:18:26 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:18:26 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:18:26 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:18:26 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:18:27 INFO log: Logging initialized @53863ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:18:28 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:18:28 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:18:29 INFO Server: Started @55684ms
25/06/09 05:18:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:18:29 INFO AbstractConnector: Started ServerConnector@30ddca90{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:18:29 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/06/09 05:18:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4a605af3{/,null,AVAILABLE,@Spark}
25/06/09 05:18:30 INFO SecurityManager: Changing view acls to: root
25/06/09 05:18:30 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:18:30 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:18:30 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:18:33 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:18:33 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:18:33 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:18:33 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:18:33 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:18:34 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:18:35 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:18:35 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:18:35 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:18:35 INFO ResourceUtils: ==============================================================
25/06/09 05:18:35 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:18:35 INFO ResourceUtils: ==============================================================
25/06/09 05:18:35 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:18:35 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:18:35 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:18:35 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:18:35 INFO SecurityManager: Changing view acls to: root
25/06/09 05:18:35 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:18:35 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:18:35 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:18:35 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:18:35 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:18:35 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:18:36 INFO SecurityManager: Changing view acls to: root
25/06/09 05:18:36 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:18:36 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:18:36 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:18:36 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:18:36 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:18:36 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:18:36 INFO Executor: Java version 1.8.0_412
25/06/09 05:18:36 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:18:36 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@69c8b2c8 for default.
25/06/09 05:18:37 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:18:37 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:18:38 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:18:38 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:18:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34113.
25/06/09 05:18:38 INFO NettyBlockTransferService: Server created on 10.139.64.4:34113
25/06/09 05:18:38 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:18:38 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 34113, None)
25/06/09 05:18:38 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:34113 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 34113, None)
25/06/09 05:18:38 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 34113, None)
25/06/09 05:18:38 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 34113, None)
25/06/09 05:18:39 INFO Utils: Successfully started service 'sparkDriver' on port 45031.
25/06/09 05:18:39 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:18:39 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:18:39 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:18:39 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:18:39 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:18:39 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-f3008a73-8f3b-45c7-b0d7-a113c7b21d6a
25/06/09 05:18:40 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:18:40 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:18:40 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:18:40 INFO log: Logging initialized @53372ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:18:41 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:18:42 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:18:42 INFO Server: Started @54921ms
25/06/09 05:18:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:18:43 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/06/09 05:18:43 INFO AbstractConnector: Started ServerConnector@583c8e5b{HTTP/1.1, (http/1.1)}{10.139.64.4:4042}
25/06/09 05:18:43 INFO Utils: Successfully started service 'SparkUI' on port 4042.
25/06/09 05:18:43 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@731761c1{/,null,AVAILABLE,@Spark}
25/06/09 05:18:46 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:18:47 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:18:47 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:18:47 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:18:47 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:18:49 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:18:49 INFO SecurityManager: Changing view acls to: root
25/06/09 05:18:49 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:18:49 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:18:49 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:18:49 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:18:50 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:18:50 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:18:50 INFO Executor: Java version 1.8.0_412
25/06/09 05:18:50 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:18:50 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@78c124fd for default.
25/06/09 05:18:50 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:18:50 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:18:51 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@4a605af3{/,null,STOPPED,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3b23cdbd{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@624aea14{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@657343d1{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@631947b8{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@51285c18{/stages,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@48b0cb13{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@66e79817{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2fe027b3{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@54cf892f{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@28b6ed83{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1ace3a36{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2f1e1862{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7467dd90{/storage,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@42df0f0b{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@d563f1a{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@44ab4b79{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5fc27c{/environment,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@556b15b2{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7be418ff{/executors,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@163384dc{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7b1b19bc{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2c85cb54{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3158d34d{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@401d54f8{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4a8aebf1{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@255b592a{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@79c0f0a7{/static,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@74234c5e{/,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@68d6161d{/api,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5f9cd017{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@34be202b{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6f27bab7{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:18:51 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@55de94a8{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:18:51 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:18:51 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:18:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43649.
25/06/09 05:18:51 INFO NettyBlockTransferService: Server created on 10.139.64.4:43649
25/06/09 05:18:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:18:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 43649, None)
25/06/09 05:18:51 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:43649 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 43649, None)
25/06/09 05:18:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 43649, None)
25/06/09 05:18:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 43649, None)
25/06/09 05:19:02 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@731761c1{/,null,STOPPED,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@76635365{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7cdf6e7c{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@33a700ae{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2f3d49af{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@77dd4e08{/stages,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@67105c65{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4d62566d{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@55ed74b3{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4ba191d{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5befffba{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@73e883d7{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@78526f02{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@182c544f{/storage,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@d3f2372{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3487eaca{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@55ea3d86{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@a9c4dfd{/environment,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7a233f3f{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@22fb9254{/executors,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@36cfc096{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@49ed565{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2f366df1{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6bc4b16c{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3e2a246e{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@727cb587{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@434ac964{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1409276{/static,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@54d5a46b{/,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@192635a7{/api,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@76b2611c{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@64259648{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2215fd22{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:19:02 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7aa4a04c{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:19:37 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:19:37 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:19:37 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:19:37 INFO AbstractConnector: Stopped Spark@30ddca90{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:19:38 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4041
25/06/09 05:19:38 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:19:40 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:19:40 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:19:40 INFO MemoryStore: MemoryStore cleared
25/06/09 05:19:40 INFO BlockManager: BlockManager stopped
25/06/09 05:19:40 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:19:40 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:19:40 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:19:40 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:19:40 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:19:40 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:19:40 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-cf5953bd-c679-4eb9-9eb3-b075f7bf9346/pyspark-387d8a6c-ab52-4b59-83de-de47bc3787d4
25/06/09 05:19:40 INFO ShutdownHookManager: Deleting directory /tmp/spark-b62873b1-796a-4490-b3e3-466b0a109642
25/06/09 05:19:40 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-cf5953bd-c679-4eb9-9eb3-b075f7bf9346
25/06/09 05:19:41 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:19:41 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:19:41 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:19:41 INFO AbstractConnector: Stopped Spark@583c8e5b{HTTP/1.1, (http/1.1)}{10.139.64.4:4042}
25/06/09 05:19:41 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4042
25/06/09 05:19:41 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:19:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:19:44 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:19:44 INFO MemoryStore: MemoryStore cleared
25/06/09 05:19:44 INFO BlockManager: BlockManager stopped
25/06/09 05:19:44 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:19:44 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:19:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:19:44 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:19:57 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:20:00 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:20:00 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:20:03 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:20:05 INFO SecurityManager: Changing view acls to: root
25/06/09 05:20:05 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:20:05 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:20:05 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:20:08 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:20:09 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:20:09 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:20:09 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:20:09 INFO ResourceUtils: ==============================================================
25/06/09 05:20:09 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:20:09 INFO ResourceUtils: ==============================================================
25/06/09 05:20:09 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:20:10 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:20:10 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:20:10 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:20:10 INFO SecurityManager: Changing view acls to: root
25/06/09 05:20:10 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:20:10 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:20:10 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:20:10 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:20:10 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:20:12 INFO Utils: Successfully started service 'sparkDriver' on port 39705.
25/06/09 05:20:12 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:20:12 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:20:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:20:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:20:12 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:20:13 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-11cd8cf5-1e1f-473d-bf09-c58c7d49a4f3
25/06/09 05:20:13 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:20:13 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:20:13 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:20:13 INFO log: Logging initialized @29561ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:20:14 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:20:14 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:20:14 INFO Server: Started @30240ms
25/06/09 05:20:14 INFO AbstractConnector: Started ServerConnector@4501b668{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:20:14 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/09 05:20:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3d56867d{/,null,AVAILABLE,@Spark}
25/06/09 05:20:16 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:20:17 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:20:17 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:20:17 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:20:17 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:20:18 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:20:18 INFO SecurityManager: Changing view acls to: root
25/06/09 05:20:18 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:20:18 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:20:18 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:20:18 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:20:18 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:20:18 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:20:18 INFO Executor: Java version 1.8.0_412
25/06/09 05:20:18 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:20:18 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@68055025 for default.
25/06/09 05:20:19 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:20:19 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:20:20 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:20:20 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:20:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35317.
25/06/09 05:20:20 INFO NettyBlockTransferService: Server created on 10.139.64.4:35317
25/06/09 05:20:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:20:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 35317, None)
25/06/09 05:20:20 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:35317 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 35317, None)
25/06/09 05:20:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 35317, None)
25/06/09 05:20:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 35317, None)
25/06/09 05:20:29 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@3d56867d{/,null,STOPPED,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@bcbbd72{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2bb4691{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@630152a0{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@108a8144{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@34725921{/stages,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7b97a4c8{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1996dcc2{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@50cb2059{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2cb6f533{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@537e60c8{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1907132{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@90fe9c6{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@313be30e{/storage,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@53ef8a9d{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@edc2493{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4444d62a{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@476e26e6{/environment,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4e57776a{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1b1c34ff{/executors,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@42e3c181{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@e12d0b3{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@35dd65a3{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@44a04515{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@18dad13{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@674721c9{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4df2e0e2{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7807047e{/static,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@223910cc{/,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@31983a63{/api,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@58ed2bbe{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7f5a0e96{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@62b48355{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:20:29 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@591ad864{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:20:30 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:20:34 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:20:34 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:20:31 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:20:34 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:20:34 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:20:38 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:20:38 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:20:41 INFO SecurityManager: Changing view acls to: root
25/06/09 05:20:41 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:20:41 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:20:41 INFO SecurityManager: Changing view acls to: root
25/06/09 05:20:41 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:20:41 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:20:41 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:20:41 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:20:43 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:20:43 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:20:43 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:20:43 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:20:43 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:20:44 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:20:44 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:20:44 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:20:44 INFO ResourceUtils: ==============================================================
25/06/09 05:20:44 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:20:44 INFO ResourceUtils: ==============================================================
25/06/09 05:20:44 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:20:44 INFO ResourceUtils: ==============================================================
25/06/09 05:20:44 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:20:44 INFO ResourceUtils: ==============================================================
25/06/09 05:20:44 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:20:44 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:20:44 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:20:44 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:20:44 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:20:44 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:20:44 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:20:44 INFO SecurityManager: Changing view acls to: root
25/06/09 05:20:44 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:20:44 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:20:44 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:20:44 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:20:44 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:20:44 INFO SecurityManager: Changing view acls to: root
25/06/09 05:20:44 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:20:44 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:20:44 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:20:44 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:20:44 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:20:46 INFO Utils: Successfully started service 'sparkDriver' on port 42573.
25/06/09 05:20:46 INFO Utils: Successfully started service 'sparkDriver' on port 44861.
25/06/09 05:20:47 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:20:47 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:20:47 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:20:47 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:20:47 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:20:47 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:20:47 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:20:47 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:20:47 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:20:47 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:20:47 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-71f6b76e-9fa5-48a9-828b-332f3a0752ef
25/06/09 05:20:47 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-842af222-0130-4945-8aa9-1cac51481257
25/06/09 05:20:47 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:20:47 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:20:47 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:20:47 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:20:47 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:20:47 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:20:48 INFO log: Logging initialized @31631ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:20:48 INFO log: Logging initialized @31597ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:20:48 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:20:48 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:20:48 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:20:48 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:20:49 INFO Server: Started @32710ms
25/06/09 05:20:49 INFO Server: Started @32636ms
25/06/09 05:20:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:20:49 INFO AbstractConnector: Started ServerConnector@72d47b8d{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:20:49 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/06/09 05:20:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:20:49 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/06/09 05:20:49 INFO AbstractConnector: Started ServerConnector@4d21f497{HTTP/1.1, (http/1.1)}{10.139.64.4:4042}
25/06/09 05:20:49 INFO Utils: Successfully started service 'SparkUI' on port 4042.
25/06/09 05:20:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@11871181{/,null,AVAILABLE,@Spark}
25/06/09 05:20:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6a8563e5{/,null,AVAILABLE,@Spark}
25/06/09 05:20:51 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:20:52 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:20:51 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:20:52 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:20:52 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:20:52 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:20:52 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:20:52 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:20:48 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:20:52 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:20:52 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:20:52 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:20:52 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:20:52 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:20:53 INFO SecurityManager: Changing view acls to: root
25/06/09 05:20:53 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:20:53 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:20:53 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:20:53 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:20:53 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:20:53 INFO SecurityManager: Changing view acls to: root
25/06/09 05:20:53 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:20:53 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:20:53 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:20:53 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:20:53 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:20:53 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:20:53 INFO Executor: Java version 1.8.0_412
25/06/09 05:20:53 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:20:53 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:20:53 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:20:53 INFO Executor: Java version 1.8.0_412
25/06/09 05:20:53 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@8e14153 for default.
25/06/09 05:20:53 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:20:53 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4c0299a0 for default.
25/06/09 05:20:53 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:20:53 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:20:53 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:20:53 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:20:54 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:20:54 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:20:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44965.
25/06/09 05:20:54 INFO NettyBlockTransferService: Server created on 10.139.64.4:44965
25/06/09 05:20:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:20:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 44965, None)
25/06/09 05:20:54 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:44965 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 44965, None)
25/06/09 05:20:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 44965, None)
25/06/09 05:20:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 44965, None)
25/06/09 05:20:54 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:20:55 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:20:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46545.
25/06/09 05:20:55 INFO NettyBlockTransferService: Server created on 10.139.64.4:46545
25/06/09 05:20:55 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:20:55 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 46545, None)
25/06/09 05:20:55 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:46545 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 46545, None)
25/06/09 05:20:55 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 46545, None)
25/06/09 05:20:55 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 46545, None)
25/06/09 05:20:57 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:21:00 INFO SecurityManager: Changing view acls to: root
25/06/09 05:21:00 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:21:00 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:21:00 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:21:02 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:21:03 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@11871181{/,null,STOPPED,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@e9c90b6{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3ff415b9{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@71276ebf{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2c772cd9{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@570d2a35{/stages,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@232e09df{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1d2f00ea{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@350104b7{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7a3a1564{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@24661442{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2aff4cd9{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5bce2b7a{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2ca0daab{/storage,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3e2f3169{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2668fae8{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@77e643c2{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2259b1ef{/environment,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7b3bd2bf{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6a9df753{/executors,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@426a0d89{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6508c35c{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1cb9c601{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@bad4f30{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3b19cd7e{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@11a19227{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@19256382{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@50761e8d{/static,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@57a7acd3{/,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@75e90081{/api,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@6a8563e5{/,null,STOPPED,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@303c86e{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2afd2b37{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@77a6b190{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@211912d1{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5db2f210{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6aba62c4{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@47d042c4{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1bb364d1{/stages,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6fac5c12{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@21add81a{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@aa38853{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@b49f7d4{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1c1e69b1{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@60a57264{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@408c31bf{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@69d2ce7d{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@30b8e270{/storage,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3a9a9e88{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1d4f94be{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@16652e6f{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@78a8a67{/environment,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6c1b15c5{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@51bdd148{/executors,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@24b30084{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2465320f{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1c0b0e87{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@66d4a052{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6a281dc{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4e035b38{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@50a92f89{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3c6e74b7{/static,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@34e31ec9{/,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@eff5537{/api,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@c5221c{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7180a40{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1deb4376{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1f902b87{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:21:03 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:21:03 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:21:03 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:21:03 INFO ResourceUtils: ==============================================================
25/06/09 05:21:03 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:21:03 INFO ResourceUtils: ==============================================================
25/06/09 05:21:03 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:21:03 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:21:03 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:21:03 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:21:04 INFO SecurityManager: Changing view acls to: root
25/06/09 05:21:04 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:21:04 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:21:04 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:21:04 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:21:04 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:21:07 INFO Utils: Successfully started service 'sparkDriver' on port 35367.
25/06/09 05:21:07 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:21:07 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:21:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:21:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:21:07 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:21:07 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-08597c52-f8f4-4dec-bb5e-238c58119d15
25/06/09 05:21:07 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:21:08 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:21:08 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:21:08 INFO log: Logging initialized @36356ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:21:09 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:21:09 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:21:09 INFO Server: Started @37438ms
25/06/09 05:21:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:21:10 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/06/09 05:21:10 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/06/09 05:21:10 INFO AbstractConnector: Started ServerConnector@e30ea64{HTTP/1.1, (http/1.1)}{10.139.64.4:4043}
25/06/09 05:21:10 INFO Utils: Successfully started service 'SparkUI' on port 4043.
25/06/09 05:21:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2d63e0a2{/,null,AVAILABLE,@Spark}
25/06/09 05:21:12 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:21:12 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:21:12 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:21:12 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:21:13 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:21:13 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:21:13 INFO SecurityManager: Changing view acls to: root
25/06/09 05:21:13 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:21:13 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:21:13 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:21:13 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:21:13 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:21:13 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:21:13 INFO Executor: Java version 1.8.0_412
25/06/09 05:21:14 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:21:14 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5c262e13 for default.
25/06/09 05:21:14 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:21:14 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:21:14 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:21:14 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:21:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46549.
25/06/09 05:21:14 INFO NettyBlockTransferService: Server created on 10.139.64.4:46549
25/06/09 05:21:14 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:21:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 46549, None)
25/06/09 05:21:14 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:46549 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 46549, None)
25/06/09 05:21:14 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 46549, None)
25/06/09 05:21:14 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 46549, None)
25/06/09 05:21:15 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:21:15 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:21:15 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:21:15 INFO AbstractConnector: Stopped Spark@4501b668{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:21:15 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4040
25/06/09 05:21:15 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:21:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:21:18 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:21:18 INFO MemoryStore: MemoryStore cleared
25/06/09 05:21:18 INFO BlockManager: BlockManager stopped
25/06/09 05:21:18 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:21:18 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:21:18 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:21:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:21:18 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:21:18 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:21:18 INFO ShutdownHookManager: Deleting directory /tmp/spark-eed6d6d2-f831-4e5c-a624-eb9499aa9f1b
25/06/09 05:21:18 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-005bd272-2445-4c90-bdd6-e020cb49b286/pyspark-bd2bec10-de76-4515-a011-8b4143577a7f
25/06/09 05:21:18 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-005bd272-2445-4c90-bdd6-e020cb49b286
25/06/09 05:21:21 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@2d63e0a2{/,null,STOPPED,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@218d7806{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3e9a11f5{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@463c2742{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@642b743d{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7df881cf{/stages,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@568017f5{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6fa0ed75{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2e16a4c5{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@345ee7f4{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@59ae7a92{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2d541f2b{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6b99e55d{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@39b24482{/storage,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@170ec786{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1d4308da{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@48ce1ca{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@41546854{/environment,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3eb6ff07{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3d995aa1{/executors,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@57545121{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@134f5569{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@26ad0860{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@9aa4236{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3843db09{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3e6383b4{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@77cf232a{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2edd82d2{/static,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@319a6db1{/,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3592e5f1{/api,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@34a4ebcd{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3321b111{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@46ec85ef{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:21:21 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@49fa9572{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:21:35 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:21:35 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:21:35 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:21:35 INFO AbstractConnector: Stopped Spark@72d47b8d{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:21:35 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4041
25/06/09 05:21:35 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:21:36 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:21:36 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:21:36 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:21:36 INFO AbstractConnector: Stopped Spark@4d21f497{HTTP/1.1, (http/1.1)}{10.139.64.4:4042}
25/06/09 05:21:36 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4042
25/06/09 05:21:36 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:21:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:21:38 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:21:38 INFO MemoryStore: MemoryStore cleared
25/06/09 05:21:38 INFO BlockManager: BlockManager stopped
25/06/09 05:21:38 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:21:38 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:21:38 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:21:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:21:38 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:21:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:21:38 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:21:38 INFO ShutdownHookManager: Deleting directory /tmp/spark-a0c1841c-13ce-4179-8411-5f29255be4b0
25/06/09 05:21:38 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-72de58fc-b00d-41b1-b1e3-7ad811b86a68/pyspark-50b38c41-9529-417c-bc90-e298282f09d9
25/06/09 05:21:38 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-72de58fc-b00d-41b1-b1e3-7ad811b86a68
25/06/09 05:21:38 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:21:38 INFO MemoryStore: MemoryStore cleared
25/06/09 05:21:38 INFO BlockManager: BlockManager stopped
25/06/09 05:21:38 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:21:38 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:21:38 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:21:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:21:38 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:21:39 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:21:39 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-0ffb827e-0c37-45da-aa95-914bed21cdad
25/06/09 05:21:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-ef55f80b-6265-4e1f-8a54-267ac76d7b56
25/06/09 05:21:39 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-0ffb827e-0c37-45da-aa95-914bed21cdad/pyspark-f5571eb2-66b3-4e27-999b-f91f6fb19b48
25/06/09 05:21:48 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:21:48 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:21:48 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:21:48 INFO AbstractConnector: Stopped Spark@e30ea64{HTTP/1.1, (http/1.1)}{10.139.64.4:4043}
25/06/09 05:21:48 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4043
25/06/09 05:21:48 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:21:50 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:22:10 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:22:15 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:22:15 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:22:20 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:22:23 INFO SecurityManager: Changing view acls to: root
25/06/09 05:22:23 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:22:23 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:22:23 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:22:26 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:22:26 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:22:26 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:22:26 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:22:26 INFO ResourceUtils: ==============================================================
25/06/09 05:22:26 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:22:26 INFO ResourceUtils: ==============================================================
25/06/09 05:22:26 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:22:27 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:22:27 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:22:27 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:22:27 INFO SecurityManager: Changing view acls to: root
25/06/09 05:22:27 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:22:27 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:22:27 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:22:27 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:22:27 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:22:29 INFO Utils: Successfully started service 'sparkDriver' on port 41115.
25/06/09 05:22:26 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:22:29 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:22:29 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:22:30 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:22:30 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:22:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:22:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:22:30 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:22:30 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-eaf41b96-f21d-419c-bf9b-f85f2adab32a
25/06/09 05:22:30 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:22:30 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:22:30 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:22:31 INFO log: Logging initialized @37466ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:22:31 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:22:31 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:22:32 INFO Server: Started @38626ms
25/06/09 05:22:32 INFO AbstractConnector: Started ServerConnector@46a65caa{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:22:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/09 05:22:32 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@37628adb{/,null,AVAILABLE,@Spark}
25/06/09 05:22:33 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:22:35 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:22:36 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:22:36 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:22:36 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:22:36 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:22:37 INFO SecurityManager: Changing view acls to: root
25/06/09 05:22:37 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:22:37 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:22:37 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:22:37 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:22:37 INFO SecurityManager: Changing view acls to: root
25/06/09 05:22:37 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:22:37 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:22:37 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:22:37 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:22:38 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:22:38 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:22:38 INFO Executor: Java version 1.8.0_412
25/06/09 05:22:38 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:22:38 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@39c4aeb4 for default.
25/06/09 05:22:38 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:22:38 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:22:35 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:22:38 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:22:38 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:22:39 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:22:39 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:22:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43891.
25/06/09 05:22:39 INFO NettyBlockTransferService: Server created on 10.139.64.4:43891
25/06/09 05:22:39 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:22:39 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:22:39 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 43891, None)
25/06/09 05:22:39 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:43891 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 43891, None)
25/06/09 05:22:39 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 43891, None)
25/06/09 05:22:39 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 43891, None)
25/06/09 05:22:40 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:22:40 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:22:40 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:22:40 INFO ResourceUtils: ==============================================================
25/06/09 05:22:40 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:22:40 INFO ResourceUtils: ==============================================================
25/06/09 05:22:40 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:22:40 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:22:40 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:22:40 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:22:40 INFO SecurityManager: Changing view acls to: root
25/06/09 05:22:40 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:22:40 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:22:40 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:22:40 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:22:40 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:22:41 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:22:43 INFO Utils: Successfully started service 'sparkDriver' on port 43055.
25/06/09 05:22:43 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:22:43 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:22:43 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:22:43 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:22:43 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:22:43 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-3445fba8-675f-49c6-9a6d-d70cfd0df08e
25/06/09 05:22:43 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:22:44 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:22:44 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:22:44 INFO SecurityManager: Changing view acls to: root
25/06/09 05:22:44 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:22:44 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:22:44 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:22:44 INFO log: Logging initialized @32030ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:22:45 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:22:45 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:22:45 INFO Server: Started @33072ms
25/06/09 05:22:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:22:45 INFO AbstractConnector: Started ServerConnector@6c9d1c63{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:22:45 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/06/09 05:22:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@24ee55c4{/,null,AVAILABLE,@Spark}
25/06/09 05:22:46 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:22:47 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:22:47 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:22:47 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:22:47 INFO ResourceUtils: ==============================================================
25/06/09 05:22:47 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:22:47 INFO ResourceUtils: ==============================================================
25/06/09 05:22:47 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:22:47 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:22:47 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:22:47 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:22:47 INFO SecurityManager: Changing view acls to: root
25/06/09 05:22:47 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:22:47 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:22:47 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:22:47 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:22:47 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:22:47 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@37628adb{/,null,STOPPED,@Spark}
25/06/09 05:22:47 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@72753d3e{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:22:47 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@f9a4928{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:22:47 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@39d718c0{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:22:47 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@176e252d{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@483ec49{/stages,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@487f09b4{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@27178879{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6e596529{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4a305e43{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@185155bb{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7b0dd169{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7402281b{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@68879a66{/storage,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@9e7bea0{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4fbb451{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5cffc201{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@f0a1970{/environment,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@e25aa90{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@54825894{/executors,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1f060ac8{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@32f94cb4{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@37bb007{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@403f8838{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@176f011b{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4c6a2c4f{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@39ef15e2{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@14c38200{/static,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@673f5d32{/,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@642b3142{/api,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@f709fad{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@762750ff{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@354a0430{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:22:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6e8d1856{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:22:48 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:22:48 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:22:48 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:22:48 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:22:45 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:22:48 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:22:48 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:22:49 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:22:49 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:22:49 INFO SecurityManager: Changing view acls to: root
25/06/09 05:22:49 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:22:49 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:22:49 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:22:49 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:22:50 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:22:50 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:22:50 INFO Executor: Java version 1.8.0_412
25/06/09 05:22:50 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:22:50 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5472b643 for default.
25/06/09 05:22:50 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:22:50 INFO Utils: Successfully started service 'sparkDriver' on port 42861.
25/06/09 05:22:50 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:22:50 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:22:50 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:22:50 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:22:50 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:22:51 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:22:51 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-582092e2-7dcd-4146-a899-dcc1b1b777a7
25/06/09 05:22:51 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:22:51 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:22:51 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:22:51 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:22:51 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:22:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 39233.
25/06/09 05:22:51 INFO NettyBlockTransferService: Server created on 10.139.64.4:39233
25/06/09 05:22:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:22:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 39233, None)
25/06/09 05:22:51 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:39233 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 39233, None)
25/06/09 05:22:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 39233, None)
25/06/09 05:22:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 39233, None)
25/06/09 05:22:51 INFO log: Logging initialized @30134ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:22:52 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:22:52 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:22:52 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:22:52 INFO Server: Started @31422ms
25/06/09 05:22:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:22:53 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/06/09 05:22:53 INFO AbstractConnector: Started ServerConnector@1d2e225f{HTTP/1.1, (http/1.1)}{10.139.64.4:4042}
25/06/09 05:22:53 INFO Utils: Successfully started service 'SparkUI' on port 4042.
25/06/09 05:22:53 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3a507467{/,null,AVAILABLE,@Spark}
25/06/09 05:22:55 INFO SecurityManager: Changing view acls to: root
25/06/09 05:22:55 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:22:55 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:22:55 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:22:55 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:22:55 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:22:55 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:22:55 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:22:56 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:22:56 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:22:56 INFO SecurityManager: Changing view acls to: root
25/06/09 05:22:56 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:22:56 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:22:56 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:22:56 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:22:56 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:22:56 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:22:56 INFO Executor: Java version 1.8.0_412
25/06/09 05:22:56 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:22:56 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5cbca8c8 for default.
25/06/09 05:22:57 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:22:57 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:22:57 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:22:57 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:22:57 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:22:57 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:22:57 INFO ResourceUtils: ==============================================================
25/06/09 05:22:57 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:22:57 INFO ResourceUtils: ==============================================================
25/06/09 05:22:57 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:22:57 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:22:57 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:22:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44181.
25/06/09 05:22:58 INFO NettyBlockTransferService: Server created on 10.139.64.4:44181
25/06/09 05:22:58 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:22:58 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:22:58 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:22:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:22:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 44181, None)
25/06/09 05:22:58 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:44181 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 44181, None)
25/06/09 05:22:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 44181, None)
25/06/09 05:22:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 44181, None)
25/06/09 05:22:58 INFO SecurityManager: Changing view acls to: root
25/06/09 05:22:58 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:22:58 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:22:58 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:22:58 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:22:58 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:22:58 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@24ee55c4{/,null,STOPPED,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@381f497b{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@71276ebf{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1d95fdae{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@362aea27{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1164e899{/stages,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4e9c9817{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1ff76e20{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@19ff8f76{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@44e880{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4f9ef2cf{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7ce9c86b{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@14904d7a{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@cb71c57{/storage,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@308598c2{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4387accd{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3e066eee{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@524f8d1{/environment,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@676185f0{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@602a8765{/executors,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@e2d8408{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@289c6b5c{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@69c29789{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@709497ca{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6c223145{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4d5b9dab{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2d23b5df{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@e0f9a11{/static,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@740622af{/,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@410a49d4{/api,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2afd2b37{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@8bf9117{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7afc0d47{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:22:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@75359ea8{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:23:00 INFO Utils: Successfully started service 'sparkDriver' on port 34343.
25/06/09 05:23:00 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:23:00 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:23:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:23:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:23:00 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:23:00 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-33826faf-cf02-4881-b7e5-f0c4b6b49dc1
25/06/09 05:23:01 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:23:01 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:23:01 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:23:01 INFO log: Logging initialized @30042ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:23:02 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:23:02 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:23:02 INFO Server: Started @30948ms
25/06/09 05:23:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:23:02 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/06/09 05:23:02 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/06/09 05:23:02 INFO AbstractConnector: Started ServerConnector@4d21f497{HTTP/1.1, (http/1.1)}{10.139.64.4:4043}
25/06/09 05:23:02 INFO Utils: Successfully started service 'SparkUI' on port 4043.
25/06/09 05:23:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@677ca0a8{/,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@3a507467{/,null,STOPPED,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2ced8af1{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4a14024{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5f2b1667{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7d93887c{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@43363f81{/stages,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5d139e5c{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4ba1dfd4{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7e14b2d0{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3b026fbd{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@38086887{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2c7df184{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3a562dc3{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2dd335ea{/storage,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6e00e051{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3c8c57e5{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2f26f0ec{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5bded989{/environment,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6910c255{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5d28f165{/executors,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@c3a4284{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5dbc5124{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@59f7c9ea{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@88dfd7a{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@54c19672{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@39336263{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@27caba8e{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4a22ee3a{/static,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@78a04bdb{/,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@29a021bd{/api,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4fda2533{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@59a39384{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@644bae6a{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:23:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4e0593ac{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:23:05 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:23:05 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:23:05 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:23:05 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:23:06 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:23:07 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:23:07 INFO SecurityManager: Changing view acls to: root
25/06/09 05:23:07 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:23:07 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:23:07 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:23:07 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:23:07 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:23:07 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:23:07 INFO Executor: Java version 1.8.0_412
25/06/09 05:23:07 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:23:07 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4800fa08 for default.
25/06/09 05:23:07 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:23:07 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:23:08 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:23:08 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:23:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45507.
25/06/09 05:23:08 INFO NettyBlockTransferService: Server created on 10.139.64.4:45507
25/06/09 05:23:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:23:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 45507, None)
25/06/09 05:23:08 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:45507 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 45507, None)
25/06/09 05:23:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 45507, None)
25/06/09 05:23:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 45507, None)
25/06/09 05:23:14 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@677ca0a8{/,null,STOPPED,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6bc4274a{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6851b4b{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3a2e1d9c{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@d9af079{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@30be841e{/stages,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6784f80{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4e2c48ea{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5dff123e{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1bad5124{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@192b1a79{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@ed3f42e{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@773b69ff{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2c6092ff{/storage,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2432b8e1{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2ad7f68d{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@41477ac8{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1522fe13{/environment,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@62fae2d{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2413111c{/executors,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@37ca68b{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@42eac90{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@53e3b7cb{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@54ac7c74{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@47170f5d{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6d96257e{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3e4eb8e0{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4d82b250{/static,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@57a2394c{/,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@c008e62{/api,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@75768091{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1e4a9b27{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4b3e2f87{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:23:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@599f4d9f{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:23:23 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:23:23 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:23:23 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:23:23 INFO AbstractConnector: Stopped Spark@46a65caa{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:23:23 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4040
25/06/09 05:23:24 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:23:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:23:26 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:23:26 INFO MemoryStore: MemoryStore cleared
25/06/09 05:23:26 INFO BlockManager: BlockManager stopped
25/06/09 05:23:26 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:23:26 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:23:26 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:23:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:23:26 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:23:26 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:23:26 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-e71fb2fd-12a8-44ba-ba66-4169be39bacc
25/06/09 05:23:26 INFO ShutdownHookManager: Deleting directory /tmp/spark-7aecdbe1-c430-444c-bea9-614789a97ab1
25/06/09 05:23:26 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-e71fb2fd-12a8-44ba-ba66-4169be39bacc/pyspark-5bf838d5-559e-4a04-a135-de5ef14c3938
25/06/09 05:23:31 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:23:31 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:23:31 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:23:31 INFO AbstractConnector: Stopped Spark@6c9d1c63{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:23:31 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4041
25/06/09 05:23:31 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:23:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:23:33 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:23:33 INFO MemoryStore: MemoryStore cleared
25/06/09 05:23:33 INFO BlockManager: BlockManager stopped
25/06/09 05:23:33 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:23:33 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:23:33 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:23:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:23:33 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:23:33 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:23:33 INFO ShutdownHookManager: Deleting directory /tmp/spark-cf681e44-f48f-40aa-9b33-7e306ec47b67
25/06/09 05:23:34 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-8e7ad399-ce2a-4421-b2f8-3d032e590b4d/pyspark-80d80b81-807e-4b21-86ad-423db5b4b6c5
25/06/09 05:23:34 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-8e7ad399-ce2a-4421-b2f8-3d032e590b4d
25/06/09 05:23:36 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:23:36 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:23:36 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:23:37 INFO AbstractConnector: Stopped Spark@1d2e225f{HTTP/1.1, (http/1.1)}{10.139.64.4:4042}
25/06/09 05:23:37 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4042
25/06/09 05:23:37 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:23:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:23:39 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:23:39 INFO MemoryStore: MemoryStore cleared
25/06/09 05:23:39 INFO BlockManager: BlockManager stopped
25/06/09 05:23:39 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:23:39 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:23:39 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:23:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:23:39 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:23:39 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:23:39 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-0d9b545f-c22a-4cd8-a41b-ae5691c71391
25/06/09 05:23:39 INFO ShutdownHookManager: Deleting directory /tmp/spark-96f33c0a-4ef9-4261-a0f2-076aa3be060e
25/06/09 05:23:39 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-0d9b545f-c22a-4cd8-a41b-ae5691c71391/pyspark-c463b7b1-f12a-4fe0-877b-526f6078f14f
25/06/09 05:23:42 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:23:42 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:23:42 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:23:42 INFO AbstractConnector: Stopped Spark@4d21f497{HTTP/1.1, (http/1.1)}{10.139.64.4:4043}
25/06/09 05:23:42 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4043
25/06/09 05:23:42 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:23:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:24:37 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:24:37 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:24:41 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:24:41 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:24:41 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:24:41 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:24:40 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:24:43 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:24:43 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:24:44 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:24:45 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:24:46 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:24:47 INFO SecurityManager: Changing view acls to: root
25/06/09 05:24:47 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:24:47 INFO SecurityManager: Changing view acls to: root
25/06/09 05:24:47 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:24:47 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:24:47 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:24:47 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:24:47 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:24:45 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:24:48 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:24:48 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:24:48 INFO SecurityManager: Changing view acls to: root
25/06/09 05:24:48 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:24:48 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:24:48 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:24:49 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:24:49 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:24:50 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:24:50 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:24:50 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:24:50 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:24:50 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:24:50 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:24:50 INFO ResourceUtils: ==============================================================
25/06/09 05:24:50 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:24:50 INFO ResourceUtils: ==============================================================
25/06/09 05:24:50 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:24:50 INFO ResourceUtils: ==============================================================
25/06/09 05:24:50 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:24:50 INFO ResourceUtils: ==============================================================
25/06/09 05:24:50 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:24:50 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:24:50 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:24:50 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:24:50 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:24:50 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:24:50 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:24:51 INFO SecurityManager: Changing view acls to: root
25/06/09 05:24:51 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:24:51 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:24:51 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:24:51 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:24:51 INFO SecurityManager: Changing view acls to: root
25/06/09 05:24:51 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:24:51 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:24:51 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:24:51 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:24:51 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:24:51 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:24:51 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:24:51 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:24:51 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:24:51 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:24:51 INFO ResourceUtils: ==============================================================
25/06/09 05:24:51 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:24:51 INFO ResourceUtils: ==============================================================
25/06/09 05:24:51 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:24:52 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:24:52 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:24:52 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:24:52 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:24:52 INFO SecurityManager: Changing view acls to: root
25/06/09 05:24:52 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:24:52 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:24:52 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:24:52 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:24:52 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:24:53 INFO Utils: Successfully started service 'sparkDriver' on port 35997.
25/06/09 05:24:53 INFO Utils: Successfully started service 'sparkDriver' on port 35639.
25/06/09 05:24:53 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:24:53 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:24:53 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:24:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:24:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:24:53 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:24:53 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-6fa966b1-4ab8-48dc-828c-f427618a646f
25/06/09 05:24:53 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:24:53 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:24:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:24:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:24:53 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:24:53 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:24:53 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-cdb99b43-4006-41ac-a20a-885b5f50396f
25/06/09 05:24:54 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:24:54 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:24:54 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:24:54 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:24:54 INFO SecurityManager: Changing view acls to: root
25/06/09 05:24:54 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:24:54 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:24:54 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:24:54 INFO log: Logging initialized @36811ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:24:54 INFO Utils: Successfully started service 'sparkDriver' on port 33435.
25/06/09 05:24:54 INFO log: Logging initialized @37108ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:24:55 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:24:55 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:24:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:24:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:24:55 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:24:55 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-05a0c217-f8a3-453f-a1c1-fbb8bd7a816b
25/06/09 05:24:55 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:24:55 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:24:55 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:24:55 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:24:55 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:24:55 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:24:55 INFO Server: Started @38128ms
25/06/09 05:24:56 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:24:56 INFO log: Logging initialized @29946ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:24:56 INFO Server: Started @38669ms
25/06/09 05:24:56 INFO AbstractConnector: Started ServerConnector@7c5bf0d5{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:24:56 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/09 05:24:56 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:24:56 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2cbb93da{/,null,AVAILABLE,@Spark}
25/06/09 05:24:56 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:24:56 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:24:57 INFO AbstractConnector: Started ServerConnector@38b65d55{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:24:57 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/06/09 05:24:57 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:24:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@21bfe2f7{/,null,AVAILABLE,@Spark}
25/06/09 05:24:57 INFO Server: Started @31130ms
25/06/09 05:24:57 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:24:57 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:24:57 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:24:57 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:24:57 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/06/09 05:24:57 INFO ResourceUtils: ==============================================================
25/06/09 05:24:57 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:24:57 INFO ResourceUtils: ==============================================================
25/06/09 05:24:57 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:24:57 INFO AbstractConnector: Started ServerConnector@1950f860{HTTP/1.1, (http/1.1)}{10.139.64.4:4042}
25/06/09 05:24:57 INFO Utils: Successfully started service 'SparkUI' on port 4042.
25/06/09 05:24:58 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:24:58 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:24:58 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:24:58 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@677ca0a8{/,null,AVAILABLE,@Spark}
25/06/09 05:24:58 INFO SecurityManager: Changing view acls to: root
25/06/09 05:24:58 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:24:58 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:24:58 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:24:58 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:24:58 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:24:59 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:24:59 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:24:59 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:24:59 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:24:59 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:24:59 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:24:59 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:24:59 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:25:00 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:25:00 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:25:00 INFO Utils: Successfully started service 'sparkDriver' on port 46691.
25/06/09 05:25:00 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:25:00 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:25:00 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:25:00 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:25:01 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:25:01 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:25:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:25:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:25:01 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:25:01 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:25:01 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:25:01 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-162be553-c6a5-45e1-bdba-0f5a36a87b23
25/06/09 05:25:01 INFO SecurityManager: Changing view acls to: root
25/06/09 05:25:01 INFO SecurityManager: Changing view acls to: root
25/06/09 05:25:01 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:25:01 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:25:01 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:25:01 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:25:01 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:25:01 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:25:01 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:25:01 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:25:01 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:25:01 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:25:01 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:25:01 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:25:01 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:25:01 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:25:01 INFO Executor: Java version 1.8.0_412
25/06/09 05:25:01 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:25:01 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:25:01 INFO Executor: Java version 1.8.0_412
25/06/09 05:25:01 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:25:01 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4fe30e53 for default.
25/06/09 05:25:01 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:25:01 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1edf713a for default.
25/06/09 05:25:02 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:25:02 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:25:02 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:25:02 INFO SecurityManager: Changing view acls to: root
25/06/09 05:25:02 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:25:02 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:25:02 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:25:02 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:25:02 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:25:02 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:25:02 INFO log: Logging initialized @31123ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:25:02 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:25:02 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:25:02 INFO Executor: Java version 1.8.0_412
25/06/09 05:25:02 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:25:02 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@2ab551b2 for default.
25/06/09 05:25:02 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:25:02 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:25:02 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:25:02 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:25:02 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:25:02 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:25:02 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:25:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35485.
25/06/09 05:25:02 INFO NettyBlockTransferService: Server created on 10.139.64.4:35485
25/06/09 05:25:02 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:25:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36175.
25/06/09 05:25:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 35485, None)
25/06/09 05:25:03 INFO NettyBlockTransferService: Server created on 10.139.64.4:36175
25/06/09 05:25:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:25:03 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:35485 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 35485, None)
25/06/09 05:25:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 36175, None)
25/06/09 05:25:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 35485, None)
25/06/09 05:25:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 35485, None)
25/06/09 05:25:03 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:36175 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 36175, None)
25/06/09 05:25:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 36175, None)
25/06/09 05:25:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 36175, None)
25/06/09 05:25:03 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:25:03 INFO Server: Started @32461ms
25/06/09 05:25:03 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:25:03 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:25:03 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42127.
25/06/09 05:25:03 INFO NettyBlockTransferService: Server created on 10.139.64.4:42127
25/06/09 05:25:03 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:25:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:25:03 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 42127, None)
25/06/09 05:25:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/06/09 05:25:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/06/09 05:25:03 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:42127 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 42127, None)
25/06/09 05:25:03 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 42127, None)
25/06/09 05:25:03 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 42127, None)
25/06/09 05:25:03 INFO AbstractConnector: Started ServerConnector@372464ef{HTTP/1.1, (http/1.1)}{10.139.64.4:4043}
25/06/09 05:25:03 INFO Utils: Successfully started service 'SparkUI' on port 4043.
25/06/09 05:25:04 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2f8c9da7{/,null,AVAILABLE,@Spark}
25/06/09 05:25:05 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:25:05 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:25:06 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:25:06 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:25:06 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:25:06 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:25:07 INFO SecurityManager: Changing view acls to: root
25/06/09 05:25:07 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:25:07 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:25:07 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:25:07 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:25:07 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:25:07 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:25:07 INFO Executor: Java version 1.8.0_412
25/06/09 05:25:07 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:25:07 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@392d3b71 for default.
25/06/09 05:25:07 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:25:07 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:25:08 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:25:08 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:25:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45555.
25/06/09 05:25:08 INFO NettyBlockTransferService: Server created on 10.139.64.4:45555
25/06/09 05:25:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:25:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 45555, None)
25/06/09 05:25:08 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:45555 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 45555, None)
25/06/09 05:25:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 45555, None)
25/06/09 05:25:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 45555, None)
25/06/09 05:25:10 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@677ca0a8{/,null,STOPPED,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@188249cd{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7adc600b{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@14df16d1{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7ab6b429{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5c3b6546{/stages,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@49a0a49a{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@264a1c1{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@376a243b{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3ce08139{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7f06ae9b{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@36824584{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3d0363f5{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@21bfe2f7{/,null,STOPPED,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@8ea5c92{/storage,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@371528b7{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2087b59{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2cfd64e7{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@70832189{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@43631503{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@54030a{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3b940b39{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7c441a57{/environment,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@26c3b1b1{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@37910b4c{/stages,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7859316b{/executors,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5c178053{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3889d16c{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2acb8259{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@354d0717{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@309a3358{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@25171e6a{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@788715f6{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2531e1bb{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@984ac49{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2f827314{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@41d4a05e{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@45bd3a89{/storage,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5a6ead9b{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5ff63c64{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@556ddfbd{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@41dc2a61{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@25a454ac{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@11e3c8c7{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@21c3d4ef{/environment,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@178e21dd{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@71653bb0{/executors,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@47e9f4cb{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@26dfd594{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@72843447{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2a5ace69{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1d4bf0ce{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1da57196{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@67b6cc4a{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6d2d16a3{/static,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@58817f74{/,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@36ac3050{/static,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@796ebae4{/,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@a46cb61{/api,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6affd58a{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5ff9e277{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1ef538c3{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@27c32924{/api,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@35216529{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4db89bd0{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7f560d71{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2cae932a{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3e2d2a21{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@2cbb93da{/,null,STOPPED,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5b115831{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7cb79f7f{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6fc65abb{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7936c80d{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2b306118{/stages,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@185d24d0{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@301f2b37{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1c77fbaa{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3b60b1c8{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6461e206{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5386a0da{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@38ab0f49{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@651dad3{/storage,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@38b82f03{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@696aab18{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@55f9553{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@736b7f98{/environment,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@45213260{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@be51c98{/executors,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@150943b6{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@44854ce3{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7c981e0e{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@49826b1d{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4950b539{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@42c5234f{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:25:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5ecbb300{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:25:11 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6478b9b{/static,null,AVAILABLE,@Spark}
25/06/09 05:25:11 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1e9c9245{/,null,AVAILABLE,@Spark}
25/06/09 05:25:11 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5798640f{/api,null,AVAILABLE,@Spark}
25/06/09 05:25:11 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@202a2358{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:25:11 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6a75dca8{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:25:11 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4d0f6ead{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:25:11 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2fe85ae2{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@2f8c9da7{/,null,STOPPED,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@cf0241{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7ba8c55d{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4fa4e4ab{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@b397096{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4cfe89d6{/stages,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2421d181{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2e7d8ccb{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@527ba218{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@434bd5ee{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1be633f4{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@174a2644{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@385e465d{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6ff0855a{/storage,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5a574044{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6f070d50{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@135a1798{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@74f00bd4{/environment,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3d5616be{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3d494356{/executors,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5772b89b{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@73eefec5{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@e0d21ea{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5cfacecb{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3891ae31{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5a472a99{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@16adc31b{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2c1374df{/static,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@379df9b{/,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5b698a12{/api,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7e681f48{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1cb907a0{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1d8382cc{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:25:15 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5571756a{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:25:41 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:25:42 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:25:42 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:25:42 INFO AbstractConnector: Stopped Spark@1950f860{HTTP/1.1, (http/1.1)}{10.139.64.4:4042}
25/06/09 05:25:42 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4042
25/06/09 05:25:42 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:25:42 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:25:42 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:25:42 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:25:42 INFO AbstractConnector: Stopped Spark@38b65d55{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:25:42 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4041
25/06/09 05:25:42 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:25:42 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:25:42 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:25:42 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:25:42 INFO AbstractConnector: Stopped Spark@7c5bf0d5{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:25:42 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4040
25/06/09 05:25:42 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:25:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:25:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:25:44 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:25:44 INFO MemoryStore: MemoryStore cleared
25/06/09 05:25:44 INFO BlockManager: BlockManager stopped
25/06/09 05:25:44 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:25:44 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:25:44 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:25:44 INFO MemoryStore: MemoryStore cleared
25/06/09 05:25:44 INFO BlockManager: BlockManager stopped
25/06/09 05:25:44 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:25:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:25:44 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:25:44 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:25:44 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:25:44 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:25:44 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:25:44 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:25:44 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:25:44 INFO ShutdownHookManager: Deleting directory /tmp/spark-db796c73-c5ef-4b57-91ec-f4620cd9813c
25/06/09 05:25:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:25:44 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-1a70e6b4-bd24-4814-ace3-af765b0275f1/pyspark-b1824426-379a-4043-9542-6bfd99499730
25/06/09 05:25:44 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-1a70e6b4-bd24-4814-ace3-af765b0275f1
25/06/09 05:25:44 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:25:45 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-785d3c53-0735-477d-b2de-1a8b389b8e02/pyspark-d2dcc1a5-49f7-445c-be80-ed15e58d4074
25/06/09 05:25:45 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-785d3c53-0735-477d-b2de-1a8b389b8e02
25/06/09 05:25:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-a981b2d4-ab0e-4082-b59f-01cea29f14a9
25/06/09 05:25:45 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:25:45 INFO MemoryStore: MemoryStore cleared
25/06/09 05:25:45 INFO BlockManager: BlockManager stopped
25/06/09 05:25:45 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:25:45 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:25:45 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:25:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:25:45 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:25:45 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:25:45 INFO ShutdownHookManager: Deleting directory /tmp/spark-37eb910c-10f0-44bd-996d-cc737f3fb023
25/06/09 05:25:45 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-136ccd70-2c7e-451b-a3d5-ec63666c01e4/pyspark-c05b38d3-c75f-409e-b229-ba2aa52ab3cd
25/06/09 05:25:45 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-136ccd70-2c7e-451b-a3d5-ec63666c01e4
25/06/09 05:25:45 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:25:45 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:25:45 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:25:45 INFO AbstractConnector: Stopped Spark@372464ef{HTTP/1.1, (http/1.1)}{10.139.64.4:4043}
25/06/09 05:25:45 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4043
25/06/09 05:25:45 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:25:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:26:30 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:26:34 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:26:34 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:26:37 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:26:40 INFO SecurityManager: Changing view acls to: root
25/06/09 05:26:40 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:26:40 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:26:40 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:26:41 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:26:42 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:26:42 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:26:42 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:26:42 INFO ResourceUtils: ==============================================================
25/06/09 05:26:42 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:26:42 INFO ResourceUtils: ==============================================================
25/06/09 05:26:42 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:26:42 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:26:42 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:26:42 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:26:42 INFO SecurityManager: Changing view acls to: root
25/06/09 05:26:42 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:26:42 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:26:42 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:26:42 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:26:42 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:26:40 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:26:43 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:26:43 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:26:45 INFO Utils: Successfully started service 'sparkDriver' on port 45393.
25/06/09 05:26:45 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:26:45 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:26:45 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:26:45 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:26:45 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:26:45 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-ef0e4aaa-6e18-4e55-88c0-e763a0633628
25/06/09 05:26:45 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:26:45 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:26:45 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:26:46 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:26:46 INFO log: Logging initialized @30125ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:26:47 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:26:47 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:26:47 INFO Server: Started @31441ms
25/06/09 05:26:48 INFO AbstractConnector: Started ServerConnector@1071edec{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:26:48 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/09 05:26:48 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7a899867{/,null,AVAILABLE,@Spark}
25/06/09 05:26:48 INFO SecurityManager: Changing view acls to: root
25/06/09 05:26:48 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:26:48 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:26:48 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:26:50 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:26:50 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:26:50 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:26:50 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:26:50 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:26:50 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:26:51 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:26:51 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:26:51 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:26:51 INFO ResourceUtils: ==============================================================
25/06/09 05:26:51 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:26:51 INFO ResourceUtils: ==============================================================
25/06/09 05:26:51 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:26:51 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:26:51 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:26:51 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:26:51 INFO SecurityManager: Changing view acls to: root
25/06/09 05:26:51 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:26:51 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:26:51 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:26:51 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:26:51 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:26:51 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:26:51 INFO SecurityManager: Changing view acls to: root
25/06/09 05:26:51 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:26:51 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:26:51 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:26:51 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:26:51 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:26:51 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:26:51 INFO Executor: Java version 1.8.0_412
25/06/09 05:26:51 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:26:51 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@7e8a7101 for default.
25/06/09 05:26:51 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:26:51 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:26:52 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:26:52 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:26:52 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40279.
25/06/09 05:26:52 INFO NettyBlockTransferService: Server created on 10.139.64.4:40279
25/06/09 05:26:52 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:26:52 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 40279, None)
25/06/09 05:26:52 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:40279 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 40279, None)
25/06/09 05:26:52 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 40279, None)
25/06/09 05:26:52 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 40279, None)
25/06/09 05:26:53 INFO Utils: Successfully started service 'sparkDriver' on port 35445.
25/06/09 05:26:53 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:26:53 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:26:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:26:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:26:53 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:26:53 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-ff6789a2-6c63-48dc-9877-687b4979af65
25/06/09 05:26:53 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:26:53 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:26:53 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:26:54 INFO log: Logging initialized @24598ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:26:54 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:26:54 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:26:55 INFO Server: Started @25576ms
25/06/09 05:26:55 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:26:55 INFO AbstractConnector: Started ServerConnector@7385cdda{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:26:55 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/06/09 05:26:55 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7db03fd3{/,null,AVAILABLE,@Spark}
25/06/09 05:26:57 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:26:57 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:26:57 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:26:57 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:26:58 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:26:58 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:26:58 INFO SecurityManager: Changing view acls to: root
25/06/09 05:26:58 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:26:58 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:26:58 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:26:58 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:26:59 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:26:59 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:26:59 INFO Executor: Java version 1.8.0_412
25/06/09 05:26:59 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:26:59 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@608e5a75 for default.
25/06/09 05:26:59 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:26:59 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:26:59 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@7a899867{/,null,STOPPED,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7999a8d6{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@777bf5b7{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@69e88f0b{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@75aad7c2{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6de84bc{/stages,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@54c0f839{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@eea505b{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@30c23ffd{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7207e157{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@cf0241{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7ba8c55d{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3d825072{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@721b422f{/storage,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2417b043{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@645cb05c{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3d2de8ee{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4faf80c{/environment,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7cc57b72{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1921ac3{/executors,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1482381e{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@a337649{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@120dae7b{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@29cefe21{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@10f180a9{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@43692d9{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@736f3cd1{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@23caff70{/static,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@60f3845d{/,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@53c82f9c{/api,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@353c7ac1{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6526f453{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@59217238{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:26:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2215c920{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:27:00 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:27:00 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:27:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40003.
25/06/09 05:27:00 INFO NettyBlockTransferService: Server created on 10.139.64.4:40003
25/06/09 05:27:00 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:27:00 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 40003, None)
25/06/09 05:27:00 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:40003 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 40003, None)
25/06/09 05:27:00 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 40003, None)
25/06/09 05:27:00 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 40003, None)
25/06/09 05:27:05 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@7db03fd3{/,null,STOPPED,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1b88d42b{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1f604d57{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2c8a33{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2914a423{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1bb7b3b{/stages,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4bd3a82f{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@240b49e6{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@381d0380{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4c485f97{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@45bf77ac{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6af434f0{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@32fc18e8{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6e65c866{/storage,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@30a6d8cc{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3cadfd91{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@25224fa2{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@533acced{/environment,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@638c76b6{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@21fbf71e{/executors,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@56374003{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1443e452{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5b9889fe{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4ffb9430{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@78da76ef{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2386d5f4{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@79079a33{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@20563b23{/static,null,AVAILABLE,@Spark}
25/06/09 05:27:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@d86490c{/,null,AVAILABLE,@Spark}
25/06/09 05:27:06 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@47efe1f2{/api,null,AVAILABLE,@Spark}
25/06/09 05:27:06 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1920a43c{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:27:06 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@570202e0{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:27:06 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4efc8ed4{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:27:06 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5f813ef{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:27:26 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:27:26 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:27:26 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:27:26 INFO AbstractConnector: Stopped Spark@1071edec{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:27:26 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4040
25/06/09 05:27:26 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:27:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:27:29 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:27:29 INFO MemoryStore: MemoryStore cleared
25/06/09 05:27:29 INFO BlockManager: BlockManager stopped
25/06/09 05:27:29 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:27:29 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:27:29 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:27:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:27:29 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:27:29 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:27:29 INFO ShutdownHookManager: Deleting directory /tmp/spark-55597ecc-cda4-4230-823f-456fbbc1a8c0
25/06/09 05:27:29 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-a52088f4-586e-4d22-bc88-14074a6472bf/pyspark-4807770b-eb10-4e37-9996-c69606b1798b
25/06/09 05:27:29 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-a52088f4-586e-4d22-bc88-14074a6472bf
25/06/09 05:27:31 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:27:31 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:27:31 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:27:31 INFO AbstractConnector: Stopped Spark@7385cdda{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:27:31 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4041
25/06/09 05:27:31 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:27:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:28:22 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:28:25 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:28:25 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:28:28 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:28:30 INFO SecurityManager: Changing view acls to: root
25/06/09 05:28:30 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:28:30 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:28:30 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:28:31 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:28:32 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:28:32 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:28:32 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:28:32 INFO ResourceUtils: ==============================================================
25/06/09 05:28:32 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:28:32 INFO ResourceUtils: ==============================================================
25/06/09 05:28:32 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:28:32 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:28:32 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:28:32 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:28:32 INFO SecurityManager: Changing view acls to: root
25/06/09 05:28:32 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:28:32 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:28:32 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:28:32 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:28:32 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:28:34 INFO Utils: Successfully started service 'sparkDriver' on port 34261.
25/06/09 05:28:34 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:28:34 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:28:34 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:28:34 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:28:34 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:28:34 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-2bcd50f4-811a-48fb-a0f8-e4532ffea2a3
25/06/09 05:28:35 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:28:35 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:28:35 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:28:35 INFO log: Logging initialized @25272ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:28:35 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:28:36 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:28:36 INFO Server: Started @26078ms
25/06/09 05:28:36 INFO AbstractConnector: Started ServerConnector@346491d2{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:28:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/09 05:28:36 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@29fffd90{/,null,AVAILABLE,@Spark}
25/06/09 05:28:38 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:28:38 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:28:38 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:28:38 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:28:39 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:28:39 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:28:39 INFO SecurityManager: Changing view acls to: root
25/06/09 05:28:39 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:28:39 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:28:39 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:28:39 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:28:40 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:28:40 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:28:40 INFO Executor: Java version 1.8.0_412
25/06/09 05:28:40 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:28:40 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@ede8082 for default.
25/06/09 05:28:40 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:28:40 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:28:40 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:28:41 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:28:41 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38237.
25/06/09 05:28:41 INFO NettyBlockTransferService: Server created on 10.139.64.4:38237
25/06/09 05:28:41 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:28:41 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 38237, None)
25/06/09 05:28:41 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:38237 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 38237, None)
25/06/09 05:28:41 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 38237, None)
25/06/09 05:28:41 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 38237, None)
25/06/09 05:28:46 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@29fffd90{/,null,STOPPED,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@77c481ed{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@49073c12{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@287055e4{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2ee0e138{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@60ea2262{/stages,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@29f7f09f{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@13499ac{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@76ce9c02{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4b5db077{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@745c6dd8{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3129f419{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@56808874{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@363c3b44{/storage,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@d18b62c{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4e4d7e40{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1384e0d0{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4b1e436e{/environment,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@818ccca{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7b96045e{/executors,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@788a5f03{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@201e6f88{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@69c38b15{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@58e3ebec{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@33b9cc08{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6ab7acaf{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6ade8a2a{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@74ad2c08{/static,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@10fedd04{/,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3faec7{/api,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@41c03927{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1a473ea5{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@515bc2e0{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:28:46 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@17be96db{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:29:13 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:29:13 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:29:13 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:29:13 INFO AbstractConnector: Stopped Spark@346491d2{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:29:13 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4040
25/06/09 05:29:13 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:29:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:30:01 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:30:04 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:30:04 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:30:08 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:30:10 INFO SecurityManager: Changing view acls to: root
25/06/09 05:30:10 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:30:10 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:30:10 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:30:12 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:30:09 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:30:12 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:30:12 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:30:12 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:30:12 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:30:12 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:30:12 INFO ResourceUtils: ==============================================================
25/06/09 05:30:12 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:30:12 INFO ResourceUtils: ==============================================================
25/06/09 05:30:12 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:30:12 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:30:12 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:30:12 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:30:13 INFO SecurityManager: Changing view acls to: root
25/06/09 05:30:13 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:30:13 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:30:13 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:30:13 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:30:13 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:30:15 INFO Utils: Successfully started service 'sparkDriver' on port 37961.
25/06/09 05:30:15 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:30:15 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:30:15 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:30:15 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:30:15 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:30:15 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-f2d4e67f-3012-4465-9e59-ecea2df07736
25/06/09 05:30:15 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:30:15 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:30:15 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:30:15 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:30:16 INFO log: Logging initialized @28940ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:30:17 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:30:17 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:30:17 INFO Server: Started @30081ms
25/06/09 05:30:18 INFO SecurityManager: Changing view acls to: root
25/06/09 05:30:18 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:30:18 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:30:18 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:30:18 INFO AbstractConnector: Started ServerConnector@346491d2{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:30:18 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/09 05:30:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@48a8efb0{/,null,AVAILABLE,@Spark}
25/06/09 05:30:20 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:30:20 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:30:20 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:30:20 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:30:20 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:30:20 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:30:20 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:30:20 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:30:20 INFO ResourceUtils: ==============================================================
25/06/09 05:30:20 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:30:20 INFO ResourceUtils: ==============================================================
25/06/09 05:30:20 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:30:20 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:30:20 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:30:20 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:30:20 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:30:21 INFO SecurityManager: Changing view acls to: root
25/06/09 05:30:21 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:30:21 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:30:21 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:30:21 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:30:21 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:30:21 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:30:21 INFO SecurityManager: Changing view acls to: root
25/06/09 05:30:21 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:30:21 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:30:21 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:30:21 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:30:21 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:30:21 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:30:21 INFO Executor: Java version 1.8.0_412
25/06/09 05:30:21 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:30:21 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@2ee9eed for default.
25/06/09 05:30:21 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:30:21 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:30:22 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:30:22 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:30:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43373.
25/06/09 05:30:22 INFO NettyBlockTransferService: Server created on 10.139.64.4:43373
25/06/09 05:30:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:30:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 43373, None)
25/06/09 05:30:22 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:43373 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 43373, None)
25/06/09 05:30:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 43373, None)
25/06/09 05:30:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 43373, None)
25/06/09 05:30:23 INFO Utils: Successfully started service 'sparkDriver' on port 39137.
25/06/09 05:30:23 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:30:23 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:30:23 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:30:23 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:30:23 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:30:23 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-836c94dd-4daf-4c4a-bf9a-a44736b74c79
25/06/09 05:30:23 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:30:23 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:30:23 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:30:24 INFO log: Logging initialized @27836ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:30:24 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:30:25 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:30:25 INFO Server: Started @29081ms
25/06/09 05:30:26 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:30:26 INFO AbstractConnector: Started ServerConnector@11d8e5f{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:30:26 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/06/09 05:30:26 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7e9b9894{/,null,AVAILABLE,@Spark}
25/06/09 05:30:28 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:30:29 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:30:29 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:30:29 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:30:29 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:30:30 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:30:30 INFO SecurityManager: Changing view acls to: root
25/06/09 05:30:30 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:30:30 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:30:30 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:30:30 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:30:30 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@48a8efb0{/,null,STOPPED,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@734cbdd5{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@31666116{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@342f1aeb{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@77c481ed{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@49073c12{/stages,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@316aae3a{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4a9f91a0{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@b72890{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1fd37690{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@17d1e0c1{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5d718ec{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6e81bdf2{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@76f0d188{/storage,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1751208c{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@41250f25{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@484b9768{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5f894681{/environment,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@197c8030{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5b659446{/executors,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6e049f90{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3cae29ef{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@422a2a46{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@363abb92{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6b61224e{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@431bb632{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@bd2b731{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@46d77ce4{/static,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@51d1bb2{/,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@524290d6{/api,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3dbe7bd7{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@49dff4ae{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@b798c67{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@482c6514{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:30:30 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:30:30 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:30:30 INFO Executor: Java version 1.8.0_412
25/06/09 05:30:30 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:30:30 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@44671425 for default.
25/06/09 05:30:30 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:30:30 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:30:31 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:30:31 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:30:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35931.
25/06/09 05:30:31 INFO NettyBlockTransferService: Server created on 10.139.64.4:35931
25/06/09 05:30:31 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:30:31 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 35931, None)
25/06/09 05:30:31 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:35931 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 35931, None)
25/06/09 05:30:31 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 35931, None)
25/06/09 05:30:31 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 35931, None)
25/06/09 05:30:37 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@7e9b9894{/,null,STOPPED,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@201e6534{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3bfbcab9{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7df1e8c8{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@138223eb{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1e777f80{/stages,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@564647bb{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@714cf097{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@23be3ccd{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@388e10e8{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5eb2a9b9{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3ca667cb{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3e46e102{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7c7ce7e4{/storage,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1324ec61{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@21cd53af{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@155bb548{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4a476f32{/environment,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@63a08a0e{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@73f65381{/executors,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@73c109da{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7c8d428d{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2306fa04{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3b06a57d{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@62c31575{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@917a0db{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@dc18fef{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1871ee4b{/static,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@353aa428{/,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3478bfdd{/api,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@424cddb7{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4158fd5d{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2efb4170{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:30:37 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@303b53e9{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:30:56 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:30:58 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:30:58 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:30:58 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:30:58 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:30:58 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:30:58 INFO AbstractConnector: Stopped Spark@346491d2{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:30:58 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4040
25/06/09 05:30:58 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:31:00 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:31:00 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:31:00 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:31:00 INFO MemoryStore: MemoryStore cleared
25/06/09 05:31:00 INFO BlockManager: BlockManager stopped
25/06/09 05:31:00 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:31:00 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:31:01 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:31:01 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:31:01 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:31:01 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:31:01 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-7651d159-0e64-40d6-8f4b-7f7a516551ee
25/06/09 05:31:01 INFO ShutdownHookManager: Deleting directory /tmp/spark-c734f725-8bc7-4a61-b857-5029e4684cc7
25/06/09 05:31:01 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-7651d159-0e64-40d6-8f4b-7f7a516551ee/pyspark-5a522deb-85f8-45bc-b54d-9be4f8555329
25/06/09 05:31:02 INFO SecurityManager: Changing view acls to: root
25/06/09 05:31:02 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:31:02 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:31:02 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:31:04 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:31:04 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:31:04 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:31:04 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:31:05 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:31:05 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:31:05 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:31:05 INFO ResourceUtils: ==============================================================
25/06/09 05:31:05 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:31:05 INFO ResourceUtils: ==============================================================
25/06/09 05:31:05 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:31:05 INFO AbstractConnector: Stopped Spark@11d8e5f{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:31:05 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4041
25/06/09 05:31:05 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:31:05 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:31:05 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:31:05 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:31:05 INFO SecurityManager: Changing view acls to: root
25/06/09 05:31:05 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:31:05 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:31:05 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:31:05 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:31:05 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:31:07 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:31:07 INFO Utils: Successfully started service 'sparkDriver' on port 46461.
25/06/09 05:31:07 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:31:07 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:31:07 INFO MemoryStore: MemoryStore cleared
25/06/09 05:31:07 INFO BlockManager: BlockManager stopped
25/06/09 05:31:07 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:31:07 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:31:07 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:31:07 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:31:07 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:31:07 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:31:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:31:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:31:07 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:31:07 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-1b50049f-6b84-4360-b2cd-e3a7b38a65b4
25/06/09 05:31:08 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:31:08 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:31:08 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:31:08 INFO ShutdownHookManager: Deleting directory /tmp/spark-154d320c-4eac-47e9-ac5c-dc26fab64648
25/06/09 05:31:08 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:31:08 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-097ed615-c847-4fa3-9a65-7361ac93708f/pyspark-b5d4c9c3-134f-47d8-8d9c-174b9fac3310
25/06/09 05:31:08 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-097ed615-c847-4fa3-9a65-7361ac93708f
25/06/09 05:31:08 INFO log: Logging initialized @23434ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:31:09 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:31:09 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:31:09 INFO Server: Started @24265ms
25/06/09 05:31:09 INFO AbstractConnector: Started ServerConnector@1071edec{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:31:09 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/09 05:31:10 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@12455d7b{/,null,AVAILABLE,@Spark}
25/06/09 05:31:11 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:31:11 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:31:11 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:31:11 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:31:12 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:31:12 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:31:12 INFO SecurityManager: Changing view acls to: root
25/06/09 05:31:12 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:31:12 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:31:12 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:31:12 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:31:12 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:31:12 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:31:12 INFO Executor: Java version 1.8.0_412
25/06/09 05:31:13 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:31:13 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@1745f732 for default.
25/06/09 05:31:13 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:31:13 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:31:13 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:31:13 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:31:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43363.
25/06/09 05:31:13 INFO NettyBlockTransferService: Server created on 10.139.64.4:43363
25/06/09 05:31:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:31:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 43363, None)
25/06/09 05:31:13 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:43363 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 43363, None)
25/06/09 05:31:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 43363, None)
25/06/09 05:31:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 43363, None)
25/06/09 05:31:19 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@12455d7b{/,null,STOPPED,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@26b38648{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@36152260{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@63c1040c{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7999a8d6{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@777bf5b7{/stages,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7e941063{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2be3c61c{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@77f725c2{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6126079b{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5db87ae5{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5fa184c2{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2eb31452{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2153fc41{/storage,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@36e8978e{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@45278f9d{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4fa4e4ab{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@b397096{/environment,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4cfe89d6{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2421d181{/executors,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@52576a4{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2e7d8ccb{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@527ba218{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@434bd5ee{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1be633f4{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@174a2644{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@385e465d{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6ff0855a{/static,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4f838b37{/,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@649cf7ba{/api,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@57cb9333{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6c95453f{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1080ecb5{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:31:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@e86d934{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:31:49 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:31:49 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:31:49 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:31:49 INFO AbstractConnector: Stopped Spark@1071edec{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:31:49 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4040
25/06/09 05:31:49 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:31:48 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:31:51 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:31:51 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:31:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:31:51 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:31:51 INFO MemoryStore: MemoryStore cleared
25/06/09 05:31:51 INFO BlockManager: BlockManager stopped
25/06/09 05:31:51 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:31:51 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:31:51 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:31:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:31:52 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:31:52 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:31:52 INFO ShutdownHookManager: Deleting directory /tmp/spark-5be54a23-7dee-4a92-b97f-1907a7fd2631
25/06/09 05:31:52 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-335a8513-3c8c-487c-9c6e-3266e758fe9a
25/06/09 05:31:52 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-335a8513-3c8c-487c-9c6e-3266e758fe9a/pyspark-16f7d36c-0b1c-412b-80fd-abfb1f24fbf0
25/06/09 05:31:54 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:31:56 INFO SecurityManager: Changing view acls to: root
25/06/09 05:31:56 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:31:56 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:31:56 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:31:57 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:31:58 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:31:58 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:31:58 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:31:58 INFO ResourceUtils: ==============================================================
25/06/09 05:31:58 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:31:58 INFO ResourceUtils: ==============================================================
25/06/09 05:31:58 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:31:58 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:31:58 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:31:58 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:31:58 INFO SecurityManager: Changing view acls to: root
25/06/09 05:31:58 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:31:58 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:31:58 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:31:58 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:31:58 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:32:01 INFO Utils: Successfully started service 'sparkDriver' on port 33979.
25/06/09 05:32:01 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:32:01 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:32:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:32:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:32:01 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:32:01 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-8ee0e677-9974-493e-ac20-c2166c61b28e
25/06/09 05:32:01 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:32:01 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:32:01 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:32:02 INFO log: Logging initialized @27583ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:32:03 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:32:03 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:32:03 INFO Server: Started @28622ms
25/06/09 05:32:04 INFO AbstractConnector: Started ServerConnector@4501b668{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:32:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/09 05:32:04 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3d56867d{/,null,AVAILABLE,@Spark}
25/06/09 05:32:06 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:32:06 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:32:06 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:32:06 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:32:07 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:32:07 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:32:07 INFO SecurityManager: Changing view acls to: root
25/06/09 05:32:07 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:32:07 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:32:07 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:32:07 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:32:07 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:32:07 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:32:07 INFO Executor: Java version 1.8.0_412
25/06/09 05:32:08 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:32:08 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@68055025 for default.
25/06/09 05:32:08 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:32:08 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:32:08 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:32:08 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:32:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45345.
25/06/09 05:32:09 INFO NettyBlockTransferService: Server created on 10.139.64.4:45345
25/06/09 05:32:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:32:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 45345, None)
25/06/09 05:32:09 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:45345 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 45345, None)
25/06/09 05:32:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 45345, None)
25/06/09 05:32:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 45345, None)
25/06/09 05:32:11 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:32:14 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:32:14 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:32:14 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@3d56867d{/,null,STOPPED,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@bcbbd72{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2bb4691{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@630152a0{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@108a8144{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@34725921{/stages,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7b97a4c8{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1996dcc2{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@50cb2059{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2cb6f533{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@537e60c8{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1907132{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@90fe9c6{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@313be30e{/storage,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@53ef8a9d{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@edc2493{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4444d62a{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@476e26e6{/environment,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4e57776a{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1b1c34ff{/executors,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@42e3c181{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@e12d0b3{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@35dd65a3{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@44a04515{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@18dad13{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@674721c9{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4df2e0e2{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7807047e{/static,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@223910cc{/,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@31983a63{/api,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@58ed2bbe{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7f5a0e96{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@62b48355{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:32:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@591ad864{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:32:17 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:32:19 INFO SecurityManager: Changing view acls to: root
25/06/09 05:32:19 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:32:19 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:32:19 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:32:21 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:32:22 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:32:22 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:32:22 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:32:23 INFO ResourceUtils: ==============================================================
25/06/09 05:32:23 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:32:23 INFO ResourceUtils: ==============================================================
25/06/09 05:32:23 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:32:23 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:32:23 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:32:23 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:32:23 INFO SecurityManager: Changing view acls to: root
25/06/09 05:32:23 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:32:23 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:32:23 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:32:23 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:32:23 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:32:26 INFO Utils: Successfully started service 'sparkDriver' on port 42281.
25/06/09 05:32:26 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:32:26 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:32:26 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:32:26 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:32:26 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:32:26 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-b1bd4af3-fd94-4994-b8da-eb8b2e1cb633
25/06/09 05:32:26 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:32:26 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:32:27 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:32:27 INFO log: Logging initialized @29556ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:32:28 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:32:29 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:32:29 INFO Server: Started @31184ms
25/06/09 05:32:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:32:29 INFO AbstractConnector: Started ServerConnector@7385cdda{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:32:29 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/06/09 05:32:30 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@118013d6{/,null,AVAILABLE,@Spark}
25/06/09 05:32:32 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:32:33 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:32:33 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:32:33 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:32:33 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:32:34 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:32:34 INFO SecurityManager: Changing view acls to: root
25/06/09 05:32:34 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:32:34 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:32:34 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:32:34 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:32:35 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:32:35 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:32:35 INFO Executor: Java version 1.8.0_412
25/06/09 05:32:35 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:32:35 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@491beb94 for default.
25/06/09 05:32:35 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:32:35 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:32:36 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:32:36 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:32:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46437.
25/06/09 05:32:36 INFO NettyBlockTransferService: Server created on 10.139.64.4:46437
25/06/09 05:32:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:32:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 46437, None)
25/06/09 05:32:36 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:46437 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 46437, None)
25/06/09 05:32:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 46437, None)
25/06/09 05:32:36 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 46437, None)
25/06/09 05:32:45 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@118013d6{/,null,STOPPED,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1b88d42b{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1f604d57{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2c8a33{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2914a423{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1bb7b3b{/stages,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4bd3a82f{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@240b49e6{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@381d0380{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4c485f97{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@45bf77ac{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6af434f0{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@32fc18e8{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6e65c866{/storage,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@30a6d8cc{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3cadfd91{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@25224fa2{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@533acced{/environment,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@638c76b6{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@21fbf71e{/executors,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@56374003{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1443e452{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5b9889fe{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4ffb9430{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@78da76ef{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2386d5f4{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@79079a33{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@20563b23{/static,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@d86490c{/,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@47efe1f2{/api,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1920a43c{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@570202e0{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4efc8ed4{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:32:45 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5f813ef{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:32:51 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:32:51 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:32:51 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:32:51 INFO AbstractConnector: Stopped Spark@4501b668{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:32:51 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4040
25/06/09 05:32:51 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:32:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:32:54 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:32:54 INFO MemoryStore: MemoryStore cleared
25/06/09 05:32:54 INFO BlockManager: BlockManager stopped
25/06/09 05:32:54 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:32:54 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:32:54 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:32:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:32:54 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:32:55 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:32:55 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-687a705c-1770-429c-8e03-0f3243102efe
25/06/09 05:32:55 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-687a705c-1770-429c-8e03-0f3243102efe/pyspark-183efe48-a097-4dc8-af71-77295adcbd1e
25/06/09 05:32:55 INFO ShutdownHookManager: Deleting directory /tmp/spark-1e4338b5-8e92-4a7f-bf33-d38debf12344
25/06/09 05:34:09 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:34:13 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:34:13 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:34:18 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:34:21 INFO SecurityManager: Changing view acls to: root
25/06/09 05:34:21 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:34:21 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:34:21 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:34:24 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:34:26 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:34:26 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:34:26 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:34:26 INFO ResourceUtils: ==============================================================
25/06/09 05:34:26 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:34:26 INFO ResourceUtils: ==============================================================
25/06/09 05:34:26 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:34:26 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:34:26 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:34:26 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:34:26 INFO SecurityManager: Changing view acls to: root
25/06/09 05:34:26 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:34:26 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:34:26 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:34:26 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:34:26 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:34:30 INFO Utils: Successfully started service 'sparkDriver' on port 40381.
25/06/09 05:34:30 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:34:30 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:34:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:34:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:34:30 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:34:30 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-f598eef5-eb8d-45d1-a177-bcdaa0884f54
25/06/09 05:34:30 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:34:30 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:34:31 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:34:31 INFO log: Logging initialized @40083ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:34:32 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:34:32 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:34:32 INFO Server: Started @41302ms
25/06/09 05:34:33 INFO AbstractConnector: Started ServerConnector@4928b9db{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:34:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/09 05:34:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@27434cfb{/,null,AVAILABLE,@Spark}
25/06/09 05:34:36 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:34:36 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:34:36 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:34:36 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:34:37 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:34:38 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:34:38 INFO SecurityManager: Changing view acls to: root
25/06/09 05:34:38 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:34:38 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:34:38 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:34:38 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:34:38 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:34:38 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:34:38 INFO Executor: Java version 1.8.0_412
25/06/09 05:34:38 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:34:38 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@a71b891 for default.
25/06/09 05:34:39 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:34:39 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:34:40 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:34:40 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:34:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33101.
25/06/09 05:34:40 INFO NettyBlockTransferService: Server created on 10.139.64.4:33101
25/06/09 05:34:40 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:34:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 33101, None)
25/06/09 05:34:40 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:33101 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 33101, None)
25/06/09 05:34:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 33101, None)
25/06/09 05:34:40 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 33101, None)
25/06/09 05:34:36 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:34:41 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:34:41 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:34:45 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:34:48 INFO SecurityManager: Changing view acls to: root
25/06/09 05:34:48 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:34:48 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:34:48 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:34:49 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@27434cfb{/,null,STOPPED,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@19373260{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@462f7363{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4ea85294{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@719cfd78{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7bdcbc11{/stages,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1241b62e{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4d4edd5{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@a3fed95{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6c9a7b60{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7eaa5a97{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@126c0c76{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@57320569{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@197f66a1{/storage,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@218d7806{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3e9a11f5{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@b36bf56{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@28c793c9{/environment,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5ad9abe1{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@69b51c62{/executors,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@41113867{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@39c96a06{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@27ba32e6{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5cfd625b{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4205ce9b{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6ef63446{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:34:49 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@41496d0c{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:34:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3412b86c{/static,null,AVAILABLE,@Spark}
25/06/09 05:34:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2edd82d2{/,null,AVAILABLE,@Spark}
25/06/09 05:34:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@603b1043{/api,null,AVAILABLE,@Spark}
25/06/09 05:34:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@683b9498{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:34:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2ab6304c{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:34:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5e6c79e6{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:34:50 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5b8bb{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:34:51 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:34:52 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:34:52 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:34:52 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:34:52 INFO ResourceUtils: ==============================================================
25/06/09 05:34:52 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:34:52 INFO ResourceUtils: ==============================================================
25/06/09 05:34:52 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:34:52 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:34:52 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:34:52 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:34:53 INFO SecurityManager: Changing view acls to: root
25/06/09 05:34:53 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:34:53 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:34:53 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:34:53 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:34:53 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:34:56 INFO Utils: Successfully started service 'sparkDriver' on port 37895.
25/06/09 05:34:56 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:34:56 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:34:56 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:34:56 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:34:56 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:34:56 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-43490e68-e0b7-4604-a6fc-0136e58ec9f0
25/06/09 05:34:56 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:34:56 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:34:56 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:34:57 INFO log: Logging initialized @38456ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:34:57 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:34:57 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:34:58 INFO Server: Started @39439ms
25/06/09 05:34:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:34:58 INFO AbstractConnector: Started ServerConnector@43c51d60{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:34:58 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/06/09 05:34:59 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5081433f{/,null,AVAILABLE,@Spark}
25/06/09 05:35:01 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:35:01 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:35:01 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:35:01 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:35:02 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:35:03 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:35:03 INFO SecurityManager: Changing view acls to: root
25/06/09 05:35:03 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:35:03 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:35:03 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:35:03 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:35:03 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:35:03 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:35:03 INFO Executor: Java version 1.8.0_412
25/06/09 05:35:03 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:35:03 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@6a083fbf for default.
25/06/09 05:35:04 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:35:04 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:35:05 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:35:05 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:35:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40961.
25/06/09 05:35:05 INFO NettyBlockTransferService: Server created on 10.139.64.4:40961
25/06/09 05:35:05 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:35:05 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 40961, None)
25/06/09 05:35:05 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:40961 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 40961, None)
25/06/09 05:35:05 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 40961, None)
25/06/09 05:35:05 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 40961, None)
25/06/09 05:35:13 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@5081433f{/,null,STOPPED,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7e193f2d{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@45b10d1d{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@491dd3bb{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5b19c14d{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@295977db{/stages,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@772e18d7{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4cd28817{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4d2ec97{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@79c85e6c{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4eafedd2{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@43588f15{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7f0a19ba{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@44639e38{/storage,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@708ce31d{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4f6eed7d{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@20c5db1a{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2ef5bd97{/environment,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@25b298aa{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@75ca307d{/executors,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@635407c8{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@300fc334{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@34640159{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7cd82e77{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@76e00cca{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7bad818d{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:35:13 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3a48001f{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:35:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@36fb29dc{/static,null,AVAILABLE,@Spark}
25/06/09 05:35:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4e466f8c{/,null,AVAILABLE,@Spark}
25/06/09 05:35:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@121ffbeb{/api,null,AVAILABLE,@Spark}
25/06/09 05:35:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5558e1fa{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:35:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3a7d7ec7{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:35:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3dc84ddf{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:35:14 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2570febb{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:35:31 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:35:31 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:35:32 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:35:32 INFO AbstractConnector: Stopped Spark@4928b9db{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:35:32 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4040
25/06/09 05:35:32 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:35:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:35:34 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:35:34 INFO MemoryStore: MemoryStore cleared
25/06/09 05:35:34 INFO BlockManager: BlockManager stopped
25/06/09 05:35:34 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:35:34 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:35:34 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:35:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:35:34 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:35:35 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:35:35 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-dedeb655-e997-469d-a64b-ccd9e5fff5f8
25/06/09 05:35:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-00c368f4-9c55-4ed7-84be-34d585579f54
25/06/09 05:35:35 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-dedeb655-e997-469d-a64b-ccd9e5fff5f8/pyspark-c485192b-1bda-49af-8f9c-fcac6315d899
25/06/09 05:35:53 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:35:53 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:35:53 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:35:53 INFO AbstractConnector: Stopped Spark@43c51d60{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:35:54 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4041
25/06/09 05:35:54 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:35:56 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:36:52 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:36:57 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:36:57 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:37:02 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:37:05 INFO SecurityManager: Changing view acls to: root
25/06/09 05:37:05 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:37:05 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:37:05 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:37:08 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:37:09 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:37:09 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:37:09 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:37:09 INFO ResourceUtils: ==============================================================
25/06/09 05:37:09 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:37:09 INFO ResourceUtils: ==============================================================
25/06/09 05:37:09 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:37:10 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:37:10 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:37:10 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:37:10 INFO SecurityManager: Changing view acls to: root
25/06/09 05:37:10 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:37:10 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:37:10 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:37:10 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:37:10 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:37:13 INFO Utils: Successfully started service 'sparkDriver' on port 45621.
25/06/09 05:37:13 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:37:13 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:37:13 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:37:13 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:37:14 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:37:14 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-f614fa9e-fe0f-4232-b374-65949f98d024
25/06/09 05:37:14 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:37:14 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:37:14 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:37:15 INFO log: Logging initialized @41117ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:37:15 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:37:16 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:37:16 INFO Server: Started @42409ms
25/06/09 05:37:16 INFO AbstractConnector: Started ServerConnector@58572543{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:37:16 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/09 05:37:17 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@62df0acd{/,null,AVAILABLE,@Spark}
25/06/09 05:37:19 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:37:20 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:37:20 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:37:20 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:37:20 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:37:22 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:37:22 INFO SecurityManager: Changing view acls to: root
25/06/09 05:37:22 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:37:22 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:37:22 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:37:22 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:37:22 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:37:22 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:37:22 INFO Executor: Java version 1.8.0_412
25/06/09 05:37:18 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:37:22 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:37:22 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@35fb1327 for default.
25/06/09 05:37:22 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:37:22 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:37:23 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:37:23 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:37:24 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:37:24 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:37:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35851.
25/06/09 05:37:24 INFO NettyBlockTransferService: Server created on 10.139.64.4:35851
25/06/09 05:37:24 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:37:24 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 35851, None)
25/06/09 05:37:24 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:35851 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 35851, None)
25/06/09 05:37:24 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 35851, None)
25/06/09 05:37:24 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 35851, None)
25/06/09 05:37:27 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:37:30 INFO SecurityManager: Changing view acls to: root
25/06/09 05:37:30 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:37:30 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:37:30 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:37:33 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:37:33 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@62df0acd{/,null,STOPPED,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@49862ca8{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1e6e5cce{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@12e3bcb{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@453d384f{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@393bccd6{/stages,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2ce3a91b{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@69d9c1fb{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5f67596a{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@38918159{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2c8a33{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2914a423{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1bb7b3b{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4bd3a82f{/storage,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@64f9e8c3{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@240b49e6{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@381d0380{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4c485f97{/environment,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@45bf77ac{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6af434f0{/executors,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@32fc18e8{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6e65c866{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@30a6d8cc{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3cadfd91{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@25224fa2{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@533acced{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@638c76b6{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@21fbf71e{/static,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3c7bfd56{/,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@60fe038a{/api,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@f787884{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@d86490c{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@47efe1f2{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4a703c88{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:37:33 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:37:33 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:37:33 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:37:34 INFO ResourceUtils: ==============================================================
25/06/09 05:37:34 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:37:34 INFO ResourceUtils: ==============================================================
25/06/09 05:37:34 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:37:34 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:37:34 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:37:34 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:37:34 INFO SecurityManager: Changing view acls to: root
25/06/09 05:37:34 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:37:34 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:37:34 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:37:34 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:37:34 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:37:37 INFO Utils: Successfully started service 'sparkDriver' on port 42541.
25/06/09 05:37:38 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:37:38 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:37:38 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:37:38 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:37:38 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:37:38 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-33239c37-1bdb-4a5d-9056-d3d03cd47297
25/06/09 05:37:38 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:37:38 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:37:38 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:37:39 INFO log: Logging initialized @39429ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:37:39 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:37:39 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:37:40 INFO Server: Started @40480ms
25/06/09 05:37:40 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:37:40 INFO AbstractConnector: Started ServerConnector@424d0eb0{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:37:40 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/06/09 05:37:41 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5c7faeb0{/,null,AVAILABLE,@Spark}
25/06/09 05:37:44 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:37:44 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:37:44 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:37:44 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:37:44 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:37:46 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:37:46 INFO SecurityManager: Changing view acls to: root
25/06/09 05:37:46 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:37:46 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:37:46 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:37:46 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:37:46 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:37:46 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:37:46 INFO Executor: Java version 1.8.0_412
25/06/09 05:37:46 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:37:46 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@2f5e3f2b for default.
25/06/09 05:37:46 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:37:46 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:37:47 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:37:47 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:37:47 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41143.
25/06/09 05:37:47 INFO NettyBlockTransferService: Server created on 10.139.64.4:41143
25/06/09 05:37:47 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:37:47 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 41143, None)
25/06/09 05:37:48 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:41143 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 41143, None)
25/06/09 05:37:48 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 41143, None)
25/06/09 05:37:48 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 41143, None)
25/06/09 05:37:57 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@5c7faeb0{/,null,STOPPED,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@45b10d1d{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@265e6d8f{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5b19c14d{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@295977db{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@772e18d7{/stages,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6c418167{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4d2ec97{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@79c85e6c{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4eafedd2{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@43588f15{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7f0a19ba{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@44639e38{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@708ce31d{/storage,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4f6eed7d{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@20c5db1a{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2ef5bd97{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@25b298aa{/environment,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@75ca307d{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@635407c8{/executors,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@300fc334{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@34640159{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7cd82e77{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@76e00cca{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7bad818d{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3a48001f{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@36fb29dc{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@46638b53{/static,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@121ffbeb{/,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@49b6cb3f{/api,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@56166b90{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3dc84ddf{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@93d2d80{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:37:57 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3b71df83{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:38:13 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:38:13 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:38:13 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:38:13 INFO AbstractConnector: Stopped Spark@58572543{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:38:13 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4040
25/06/09 05:38:13 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:38:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:38:15 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:38:15 INFO MemoryStore: MemoryStore cleared
25/06/09 05:38:15 INFO BlockManager: BlockManager stopped
25/06/09 05:38:15 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:38:15 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:38:16 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:38:16 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:38:16 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:38:16 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:38:16 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-e63267e5-929b-4053-beb5-7ba4fc35d7d7/pyspark-5f16c263-5f2f-42cd-840c-4e7ebfb3deca
25/06/09 05:38:16 INFO ShutdownHookManager: Deleting directory /tmp/spark-6343b5f3-ef34-4ff5-ba3d-ed27628771b9
25/06/09 05:38:16 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-e63267e5-929b-4053-beb5-7ba4fc35d7d7
25/06/09 05:39:43 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:39:47 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:39:47 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:39:44 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:39:48 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:39:48 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:39:52 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:39:52 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:39:55 INFO SecurityManager: Changing view acls to: root
25/06/09 05:39:55 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:39:55 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:39:55 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:39:56 INFO SecurityManager: Changing view acls to: root
25/06/09 05:39:56 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:39:56 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:39:56 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:39:57 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:39:58 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:39:58 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:39:58 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:39:58 INFO ResourceUtils: ==============================================================
25/06/09 05:39:58 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:39:58 INFO ResourceUtils: ==============================================================
25/06/09 05:39:58 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:39:58 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:39:58 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:39:58 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:39:58 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:39:59 INFO SecurityManager: Changing view acls to: root
25/06/09 05:39:59 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:39:59 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:39:59 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:39:59 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:39:59 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:39:59 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:39:59 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:39:59 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:39:59 INFO ResourceUtils: ==============================================================
25/06/09 05:39:59 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:39:59 INFO ResourceUtils: ==============================================================
25/06/09 05:39:59 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:40:00 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:40:00 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:40:00 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:40:00 INFO SecurityManager: Changing view acls to: root
25/06/09 05:40:00 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:40:00 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:40:00 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:40:00 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:40:00 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:40:01 INFO Utils: Successfully started service 'sparkDriver' on port 41877.
25/06/09 05:40:01 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:40:01 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:40:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:40:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:40:01 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:40:02 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-55442cda-a170-47ac-8d96-bc729c13aa8b
25/06/09 05:40:02 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:40:02 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:40:02 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:40:02 INFO log: Logging initialized @36619ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:40:03 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:40:04 INFO Utils: Successfully started service 'sparkDriver' on port 33473.
25/06/09 05:40:04 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:40:04 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:40:04 INFO Server: Started @38202ms
25/06/09 05:40:04 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:40:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:40:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:40:04 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:40:04 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-6192ad71-de92-4ce7-8fd5-6ac75da52eaf
25/06/09 05:40:04 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:40:04 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:40:05 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:40:05 INFO AbstractConnector: Started ServerConnector@4928b9db{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:40:05 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/09 05:40:05 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@42f70985{/,null,AVAILABLE,@Spark}
25/06/09 05:40:05 INFO log: Logging initialized @39332ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:40:06 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:40:06 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:40:06 INFO Server: Started @40584ms
25/06/09 05:40:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:40:07 INFO AbstractConnector: Started ServerConnector@38528853{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:40:07 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/06/09 05:40:07 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2b48286b{/,null,AVAILABLE,@Spark}
25/06/09 05:40:08 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:40:08 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:40:08 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:40:08 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:40:08 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:40:09 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:40:09 INFO SecurityManager: Changing view acls to: root
25/06/09 05:40:09 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:40:09 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:40:09 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:40:09 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:40:09 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:40:09 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:40:09 INFO Executor: Java version 1.8.0_412
25/06/09 05:40:09 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:40:09 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@9488efd for default.
25/06/09 05:40:10 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:40:10 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:40:10 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:40:10 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:40:10 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:40:10 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:40:10 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:40:11 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:40:11 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:40:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38237.
25/06/09 05:40:11 INFO NettyBlockTransferService: Server created on 10.139.64.4:38237
25/06/09 05:40:11 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:40:11 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 38237, None)
25/06/09 05:40:11 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:38237 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 38237, None)
25/06/09 05:40:11 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 38237, None)
25/06/09 05:40:11 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 38237, None)
25/06/09 05:40:12 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:40:12 INFO SecurityManager: Changing view acls to: root
25/06/09 05:40:12 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:40:12 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:40:12 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:40:12 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:40:13 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:40:13 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:40:13 INFO Executor: Java version 1.8.0_412
25/06/09 05:40:13 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:40:13 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@70f5c013 for default.
25/06/09 05:40:13 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:40:13 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:40:14 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:40:14 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:40:14 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46649.
25/06/09 05:40:14 INFO NettyBlockTransferService: Server created on 10.139.64.4:46649
25/06/09 05:40:14 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:40:14 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 46649, None)
25/06/09 05:40:14 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:46649 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 46649, None)
25/06/09 05:40:14 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 46649, None)
25/06/09 05:40:14 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 46649, None)
25/06/09 05:40:19 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@42f70985{/,null,STOPPED,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@64fbba49{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@c53ba29{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5f3b39a8{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@73219449{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@776c7c9a{/stages,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4a0fcff{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1bbbc84a{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6e61321f{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4f838d00{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@b0c5d26{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2d1233cf{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7b608670{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6b02d80b{/storage,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@66d330f8{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5c322ebc{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@41b1b22e{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@463c2742{/environment,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@642b743d{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7df881cf{/executors,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@568017f5{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@78de3f73{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6fa0ed75{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2e16a4c5{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@345ee7f4{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@59ae7a92{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2d541f2b{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6b99e55d{/static,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@c01cec5{/,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6ee3b8c6{/api,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@19ba5ebb{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6132e557{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1e9dfed6{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:40:19 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@c8f285d{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@2b48286b{/,null,STOPPED,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4c5a60a2{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5235816c{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@59b1da9b{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2b93cc83{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6e03ea97{/stages,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@746ed21b{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1420cd97{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@55288a3a{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@308778a8{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1f6a6eb0{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7c3a35ff{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2c176972{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6cbd1a3a{/storage,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3fd7e635{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@50001300{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1a85a5a4{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5b4f68bd{/environment,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6e4544cb{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7aca4b2e{/executors,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@34ab030a{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@407e20ef{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3f284a99{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4ace9cdc{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@59d3ddea{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@291d7ce0{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5bba4d38{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@57123e75{/static,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6ed4b759{/,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@d00b11a{/api,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@57778647{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@25947819{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3ffcedc8{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:40:24 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6942cddc{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:42:13 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:42:17 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:42:17 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:42:22 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:42:25 INFO SecurityManager: Changing view acls to: root
25/06/09 05:42:25 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:42:25 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:42:25 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:42:29 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:42:30 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:42:30 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:42:30 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:42:30 INFO ResourceUtils: ==============================================================
25/06/09 05:42:30 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:42:30 INFO ResourceUtils: ==============================================================
25/06/09 05:42:30 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:42:30 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:42:30 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:42:30 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:42:30 INFO SecurityManager: Changing view acls to: root
25/06/09 05:42:30 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:42:30 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:42:30 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:42:30 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:42:30 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:42:33 INFO Utils: Successfully started service 'sparkDriver' on port 35171.
25/06/09 05:42:33 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:42:33 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:42:33 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:42:33 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:42:33 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:42:34 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-278d9b85-137f-42d8-b6f8-e461ff207afd
25/06/09 05:42:34 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:42:34 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:42:34 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:42:35 INFO log: Logging initialized @41252ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:42:35 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:42:36 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:42:36 INFO Server: Started @42460ms
25/06/09 05:42:36 INFO AbstractConnector: Started ServerConnector@2ba16ee4{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:42:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/09 05:42:36 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5488e5a8{/,null,AVAILABLE,@Spark}
25/06/09 05:42:39 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:42:39 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:42:39 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:42:39 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:42:40 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:42:41 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:42:41 INFO SecurityManager: Changing view acls to: root
25/06/09 05:42:41 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:42:41 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:42:41 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:42:41 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:42:42 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:42:42 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:42:42 INFO Executor: Java version 1.8.0_412
25/06/09 05:42:42 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:42:42 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@629d64f1 for default.
25/06/09 05:42:42 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:42:42 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:42:43 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:42:43 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:42:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34749.
25/06/09 05:42:43 INFO NettyBlockTransferService: Server created on 10.139.64.4:34749
25/06/09 05:42:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:42:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 34749, None)
25/06/09 05:42:43 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:34749 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 34749, None)
25/06/09 05:42:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 34749, None)
25/06/09 05:42:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 34749, None)
25/06/09 05:42:40 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:42:44 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:42:44 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:42:48 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:42:51 INFO SecurityManager: Changing view acls to: root
25/06/09 05:42:51 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:42:51 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:42:51 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:42:52 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@5488e5a8{/,null,STOPPED,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6d5d9726{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@68ab6fb7{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6fa5516d{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@d362ca7{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@32f07c02{/stages,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@50ee9a03{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@bade8ab{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@31a9be46{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4009fc95{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@24202dbe{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@224e4080{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@605d8339{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7ac61781{/storage,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1b8994c4{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1befbcc2{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@570746e7{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1e835978{/environment,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@db386a9{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@16140b95{/executors,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@115aa2b8{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@73e9ea18{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@58160b30{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@19b5b553{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4d13454{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1478aef7{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@42c0badb{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2f35a33c{/static,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@79253fb1{/,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@637afe83{/api,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@612e67d0{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1946b6b2{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@11d60206{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:42:52 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@711ecaf5{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:42:55 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:42:55 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:42:55 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:42:55 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:42:56 INFO ResourceUtils: ==============================================================
25/06/09 05:42:56 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:42:56 INFO ResourceUtils: ==============================================================
25/06/09 05:42:56 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:42:56 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:42:56 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:42:56 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:42:56 INFO SecurityManager: Changing view acls to: root
25/06/09 05:42:56 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:42:56 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:42:56 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:42:56 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:42:56 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:42:59 INFO Utils: Successfully started service 'sparkDriver' on port 34149.
25/06/09 05:42:59 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:43:00 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:43:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:43:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:43:00 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:43:00 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-40286994-2f0a-4376-ade6-b71694b793f2
25/06/09 05:43:00 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:43:00 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:43:00 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:43:00 INFO log: Logging initialized @38259ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:43:01 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:43:01 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:43:02 INFO Server: Started @39525ms
25/06/09 05:43:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/06/09 05:43:02 INFO AbstractConnector: Started ServerConnector@3ecef128{HTTP/1.1, (http/1.1)}{10.139.64.4:4041}
25/06/09 05:43:02 INFO Utils: Successfully started service 'SparkUI' on port 4041.
25/06/09 05:43:03 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6a8563e5{/,null,AVAILABLE,@Spark}
25/06/09 05:43:05 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:43:05 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:43:05 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:43:05 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:43:06 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:43:07 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:43:07 INFO SecurityManager: Changing view acls to: root
25/06/09 05:43:07 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:43:07 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:43:07 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:43:07 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:43:07 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:43:07 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:43:07 INFO Executor: Java version 1.8.0_412
25/06/09 05:43:07 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:43:07 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@8e14153 for default.
25/06/09 05:43:08 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:43:08 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
25/06/09 05:43:09 WARN NativeMemoryWatchdog: Native memory watchdog is disabled by conf.
25/06/09 05:43:09 INFO TaskSchedulerImpl: Preemption disabled in FIFO scheduling mode.
25/06/09 05:43:09 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36249.
25/06/09 05:43:09 INFO NettyBlockTransferService: Server created on 10.139.64.4:36249
25/06/09 05:43:09 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/06/09 05:43:09 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.139.64.4, 36249, None)
25/06/09 05:43:09 INFO BlockManagerMasterEndpoint: Registering block manager 10.139.64.4:36249 with 366.3 MiB RAM, BlockManagerId(driver, 10.139.64.4, 36249, None)
25/06/09 05:43:09 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.139.64.4, 36249, None)
25/06/09 05:43:09 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.139.64.4, 36249, None)
25/06/09 05:43:18 INFO ContextHandler: Stopped o.e.j.s.ServletContextHandler@6a8563e5{/,null,STOPPED,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@5db2f210{/jobs,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1ac97ea{/jobs/json,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@47d042c4{/jobs/job,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1bb364d1{/jobs/job/json,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6fac5c12{/stages,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@79f967e2{/stages/json,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@aa38853{/stages/stage,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@b49f7d4{/stages/stage/json,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1c1e69b1{/stages/pool,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@408c31bf{/stages/pool/json,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@69d2ce7d{/stages/taskThreadDump,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@30b8e270{/stages/taskThreadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3a9a9e88{/storage,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1d4f94be{/storage/json,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@16652e6f{/storage/rdd,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@78a8a67{/storage/rdd/json,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6c1b15c5{/environment,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@51bdd148{/environment/json,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@24b30084{/executors,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@2465320f{/executors/json,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1c0b0e87{/executors/threadDump,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@66d4a052{/executors/threadDump/json,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6a281dc{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@4e035b38{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@50a92f89{/executors/heapHistogram,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3c6e74b7{/executors/heapHistogram/json,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@589b4752{/static,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@eff5537{/,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7b249105{/api,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@3a8140f3{/metrics,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@1deb4376{/jobs/job/kill,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@6ad05b01{/stages/stage/kill,null,AVAILABLE,@Spark}
25/06/09 05:43:18 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@37f0ece9{/metrics/json,null,AVAILABLE,@Spark}
25/06/09 05:43:32 INFO SparkContext: Invoking stop() from shutdown hook
25/06/09 05:43:32 INFO SparkContext: SparkContext is stopping with exitCode 0 from run at Executors.java:511.
25/06/09 05:43:32 WARN SparkContext: Requesting executors is not supported by current scheduler.
25/06/09 05:43:32 INFO AbstractConnector: Stopped Spark@2ba16ee4{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:43:32 INFO SparkUI: Stopped Spark web UI at http://10.139.64.4:4040
25/06/09 05:43:32 INFO DeadlockDetector: Trigger deadlock detection immediately.
25/06/09 05:43:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
25/06/09 05:43:34 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
25/06/09 05:43:34 INFO MemoryStore: MemoryStore cleared
25/06/09 05:43:34 INFO BlockManager: BlockManager stopped
25/06/09 05:43:35 INFO BlockManagerMaster: BlockManagerMaster stopped
25/06/09 05:43:35 INFO MetricsSystem: Stopping driver MetricsSystem
25/06/09 05:43:35 INFO DeadlockDetectorManager: Stopping all deadlock detection tasks.
25/06/09 05:43:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
25/06/09 05:43:35 INFO SparkContext: Successfully stopped SparkContext
25/06/09 05:43:35 INFO ShutdownHookManager: Shutdown hook called
25/06/09 05:43:35 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-754f343b-fbcd-4efe-8d35-6871adb90830
25/06/09 05:43:35 INFO ShutdownHookManager: Deleting directory /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/spark-754f343b-fbcd-4efe-8d35-6871adb90830/pyspark-8faac5f7-b5eb-43d9-847f-b3b7322918e0
25/06/09 05:43:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-2e82eee0-69db-4f5a-955b-bad87e910549
25/06/09 05:45:05 INFO DatabricksEdgeConfigs: serverlessEnabled : false
25/06/09 05:45:09 INFO DatabricksEdgeConfigs: perfPackEnabled : false
25/06/09 05:45:09 INFO DatabricksEdgeConfigs: classicSqlEnabled : false
25/06/09 05:45:13 INFO RawConfigSingleton$: Successfully loaded DB_CONF into RawConfigSingleton.
25/06/09 05:45:17 INFO SecurityManager: Changing view acls to: root
25/06/09 05:45:17 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:45:17 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:45:17 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:45:20 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:45:21 INFO SparkContext: Running Spark version 3.5.0
25/06/09 05:45:21 INFO SparkContext: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:45:21 INFO SparkContext: Java version 1.8.0_412
25/06/09 05:45:21 INFO ResourceUtils: ==============================================================
25/06/09 05:45:21 INFO ResourceUtils: No custom resources configured for spark.driver.
25/06/09 05:45:21 INFO ResourceUtils: ==============================================================
25/06/09 05:45:21 INFO SparkContext: Submitted application: pyspark-shell
25/06/09 05:45:21 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/06/09 05:45:21 INFO ResourceProfile: Limiting resource is cpu
25/06/09 05:45:21 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/06/09 05:45:21 INFO SecurityManager: Changing view acls to: root
25/06/09 05:45:21 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:45:21 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:45:21 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:45:21 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:45:21 INFO JvmCrashLogger: Past JVM crashes: detected 0, logged 0, and skipped 0 already logged
25/06/09 05:45:24 INFO Utils: Successfully started service 'sparkDriver' on port 36231.
25/06/09 05:45:25 INFO SparkEnv: Registering MapOutputTracker
25/06/09 05:45:25 INFO SparkEnv: Registering BlockManagerMaster
25/06/09 05:45:25 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/06/09 05:45:25 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/06/09 05:45:25 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/06/09 05:45:25 INFO DiskBlockManager: Created local directory at /local_disk0/blockmgr-f54985f1-adeb-40ec-9e7e-0525e07fcd1a/blockmgr-eba12990-038a-4647-b28b-7d93de7cfa0f
25/06/09 05:45:25 INFO SparkEnv: Registering OutputCommitCoordinator
25/06/09 05:45:26 WARN JfrStreamingManager: JFR streaming is only available in JDK 17+
25/06/09 05:45:26 WARN MetricsSystem: Using default name SparkStatusTracker for source because neither spark.metrics.namespace nor spark.app.id is set.
25/06/09 05:45:26 INFO log: Logging initialized @40815ms to org.eclipse.jetty.util.log.Slf4jLog
25/06/09 05:45:27 INFO JettyUtils: Start Jetty 10.139.64.4:4040 for SparkUI
25/06/09 05:45:27 INFO Server: jetty-9.4.52.v20230823; built: 2023-08-23T19:29:37.669Z; git: abdcda73818a1a2c705da276edb0bf6581e7997e; jvm 1.8.0_412-b08
25/06/09 05:45:28 INFO Server: Started @42033ms
25/06/09 05:45:28 INFO AbstractConnector: Started ServerConnector@4fedfe3a{HTTP/1.1, (http/1.1)}{10.139.64.4:4040}
25/06/09 05:45:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/06/09 05:45:28 INFO ContextHandler: Started o.e.j.s.ServletContextHandler@7235e7e2{/,null,AVAILABLE,@Spark}
25/06/09 05:45:31 ERROR SparkConnectService: Could not start Spark Connect GRPC service
java.io.IOException: Failed to bind to address 0.0.0.0/0.0.0.0:15002
	at grpc_shaded.io.grpc.netty.NettyServer.start(NettyServer.java:333)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:185)
	at grpc_shaded.io.grpc.internal.ServerImpl.start(ServerImpl.java:94)
	at org.apache.spark.sql.connect.service.SparkConnectService$.startGRPCService(SparkConnectService.scala:415)
	at org.apache.spark.sql.connect.service.SparkConnectService$.start(SparkConnectService.scala:426)
	at org.apache.spark.sql.connect.SparkConnectPlugin$$anon$1.init(SparkConnectPlugin.scala:48)
	at org.apache.spark.internal.plugin.DriverPluginContainer.$anonfun$driverPlugins$1(PluginContainer.scala:55)
	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:293)
	at scala.collection.Iterator.foreach(Iterator.scala:943)
	at scala.collection.Iterator.foreach$(Iterator.scala:943)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431)
	at scala.collection.IterableLike.foreach(IterableLike.scala:74)
	at scala.collection.IterableLike.foreach$(IterableLike.scala:73)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:56)
	at scala.collection.TraversableLike.flatMap(TraversableLike.scala:293)
	at scala.collection.TraversableLike.flatMap$(TraversableLike.scala:290)
	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:108)
	at org.apache.spark.internal.plugin.DriverPluginContainer.<init>(PluginContainer.scala:48)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:227)
	at org.apache.spark.internal.plugin.PluginContainer$.apply(PluginContainer.scala:198)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:879)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:397)
	at py4j.Gateway.invoke(Gateway.java:257)
	at py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)
	at py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)
	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:199)
	at py4j.ClientServerConnection.run(ClientServerConnection.java:119)
	at java.lang.Thread.run(Thread.java:750)
Caused by: grpc_shaded.io.netty.channel.unix.Errors$NativeIoException: bind(..) failed: Address already in use
25/06/09 05:45:31 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.sql.connect.SparkConnectPlugin.
25/06/09 05:45:31 INFO DriverPluginContainer: Initialized driver component for plugin com.databricks.spark.connect.LocalSparkConnectPlugin.
25/06/09 05:45:31 INFO DLTDebugger: Registered DLTDebuggerEndpoint at endpoint dlt-debugger
25/06/09 05:45:32 INFO LocalSparkConnectPlugin: Adjusted permissions on /databricks/sparkconnect/grpc.sock: chown:1 chmod:0
25/06/09 05:45:33 INFO DriverPluginContainer: Initialized driver component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:45:33 INFO SecurityManager: Changing view acls to: root
25/06/09 05:45:33 INFO SecurityManager: Changing modify acls to: root
25/06/09 05:45:33 INFO SecurityManager: Changing view acls groups to: 
25/06/09 05:45:33 INFO SecurityManager: Changing modify acls groups to: 
25/06/09 05:45:33 INFO SecurityManager: SecurityManager: authentication is enabled: false; ui acls disabled; users with view permissions: root groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY; RPC SSL disabled
25/06/09 05:45:34 INFO Executor: Starting executor ID driver on host 10.139.64.4
25/06/09 05:45:34 INFO Executor: OS info Linux, 6.8.0-1028-azure, amd64
25/06/09 05:45:34 INFO Executor: Java version 1.8.0_412
25/06/09 05:45:34 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
25/06/09 05:45:34 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@4d747be3 for default.
25/06/09 05:45:34 INFO ExecutorPluginContainer: Initialized executor component for plugin org.apache.spark.debugger.DLTDebuggerSparkPlugin.
25/06/09 05:45:34 INFO Utils: resolved command to be run: ArraySeq(getconf, PAGESIZE)
